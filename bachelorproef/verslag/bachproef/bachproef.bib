% Encoding: UTF-8

@Online{Martens2021,
  author       = {Martens, Marijn and De Wolf, Ralf and Evens, Tom},
  date         = {2021},
  title        = {Algoritmes en AI in de onderwijscontext: Een studie naar de perceptie, mening en houding van leerlingen en ouders in Vlaanderen},
  url          = {https://data-en-maatschappij.ai/publicaties/survey-onderwijs-2021},
  organization = {{Kenniscentrum Data en Maatschappij}},
  urldate      = {2022-03-30},
}

@Report{Crevits2022,
  author      = {Crevits, Hilde},
  date        = {2022-03-13},
  institution = {Vlaamse Overheid Departement Economie, Wetenschap en Innovatie},
  title       = {Kwart van bedrijven gebruikt artificiële intelligentie: Vlaanderen bij beste leerlingen van de klas},
  type        = {Persbericht},
  file        = {:persbericht_-_kwart_van_bedrijven_gebruikt_artificiele_intelligentie_-_vlaanderen_bij_beste_leerlingen_van_de_klas.pdf:PDF},
}

@InProceedings{Gala2016,
  author    = {Gala, N{\'u}ria and Ziegler, Johannes},
  booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity ({CL}4{LC})},
  date      = {2016},
  title     = {Reducing lexical complexity as a tool to increase text accessibility for children with dyslexia},
  pages     = {59--66},
  publisher = {The COLING 2016 Organizing Committee},
  abstract  = {Lexical complexity plays a central role in readability, particularly for dyslexic children and poor readers because of their slow and laborious decoding and word recognition skills. Although some features to aid readability may be common to most languages (e.g., the majority of {`}easy{'} words are of low frequency), we believe that lexical complexity is mainly language-specific. In this paper, we define lexical complexity for French and we present a pilot study on the effects of text simplification in dyslexic children. The participants were asked to read out loud original and manually simplified versions of a standardized French text corpus and to answer comprehension questions after reading each text. The analysis of the results shows that the simplifications performed were beneficial in terms of reading speed and they reduced the number of reading errors (mainly lexical ones) without a loss in comprehension. Although the number of participants in this study was rather small (N=10), the results are promising and contribute to the development of applications in computational linguistics.},
  address   = {Osaka, Japan},
  file      = {:Reducing lexical complexity as a tool to increase text accessibility.pdf:PDF},
  year      = {2016},
}

@InProceedings{Bingel2018,
  author    = {Bingel, Joachim and Paetzold, Gustavo and S{\o}gaard, Anders},
  booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
  date      = {2018},
  title     = {{L}exi: A tool for adaptive, personalized text simplification},
  pages     = {245--258},
  publisher = {Association for Computational Linguistics},
  abstract  = {Most previous research in text simplification has aimed to develop generic solutions, assuming very homogeneous target audiences with consistent intra-group simplification needs. We argue that this assumption does not hold, and that instead we need to develop simplification systems that adapt to the individual needs of specific users. As a first step towards personalized simplification, we propose a framework for adaptive lexical simplification and introduce Lexi, a free open-source and easily extensible tool for adaptive, personalized text simplification. Lexi is easily installed as a browser extension, enabling easy access to the service for its users.},
  address   = {Santa Fe, New Mexico, USA},
  file      = {:Lexi - A tool for adaptive, personalized text simplification.pdf:PDF},
  year      = {2018},
}

@Report{Muyters2019,
  author      = {Muyters, Philippe},
  date        = {2019-03-22},
  institution = {Vlaamse Regering},
  title       = {Vlaams Beleidsplan Artificiële Intelligentie},
  file        = {:Vlaams Beleidsplan.pdf:PDF},
}

@Online{Martens2021a,
  author       = {Martens, Marijn and De Wolf, Ralf and Evens, Tom},
  date         = {2021-06-28},
  title        = {School innovation forum 2021},
  url          = {https://data-en-maatschappij.ai/nieuws/school-innovation-forum-2021},
  organization = {{Kenniscentrum Data en Maatschappij}},
  urldate      = {2022-04-01},
}

@Online{Swayamdipta2019,
  author   = {Swabha Swayamdipta},
  date     = {2019-01-22},
  title    = {Learning Challenges in Natural Language Processing},
  url      = {https://www.microsoft.com/en-us/research/video/learning-challenges-in-natural-language-processing/},
  language = {Engels},
  urldate  = {2022-04-01},
  abstract = {As the availability of data for language learning grows, the role of linguistic structure is under scrutiny. At the same time, it is imperative to closely inspect patterns in data which might present loopholes for models to obtain high performance on benchmarks. In a two-part talk, I will address each of these challenges.
First, I will introduce the paradigm of scaffolded learning. Scaffolds enable us to leverage inductive biases from one structural source for prediction of a different, but related structure, using only as much supervision as is necessary. We show that the resulting representations achieve improved performance across a range of tasks, indicating that linguistic structure remains beneficial even with powerful deep learning architectures.
In the second part of the talk, I will showcase some of the properties exhibited by NLP models in large data regimes. Even as these models report excellent performance, sometimes claimed to beat humans, a closer look reveals that predictions are not a result of complex reasoning, and the task is not being completed in a generalizable way. Instead, this success can be largely attributed to exploitation of some artifacts of annotation in the datasets. I will discuss some questions our finding raises, as well as directions for future work.},
}

@Online{Roldos2020,
  author       = {Inés Roldós},
  date         = {2020-12-22},
  title        = {Major Challenges of Natural Language Processing (NLP)},
  url          = {https://monkeylearn.com/blog/natural-language-processing-challenges/},
  organization = {MonkeyLearn},
  urldate      = {2022-04-01},
}

@Article{Siddharthan2014,
  author  = {Siddharthan, Advaith},
  title   = {A survey of research on text simplification},
  pages   = {259-298},
  volume  = {165},
  journal = {ITL - International Journal of Applied Linguistics},
  year    = {2014},
}

@Book{Chowdhary2020,
  author    = {K.R. Chowdhary},
  date      = {2020},
  title     = {Fundamentals of Artificial Intelligence},
  publisher = {Springer, New Delhi},
}

@Online{Sciforce2020,
  author   = {{Sciforce}},
  date     = {2020-02-04},
  title    = {Biggest Open Problems in Natural Language Processing},
  url      = {https://medium.com/sciforce/biggest-open-problems-in-natural-language-processing-7eb101ccfc9},
  language = {Engels},
  urldate  = {2022-04-01},
  abstract = {The NLP domain reports great advances to the extent that a number of problems, such as part-of-speech tagging, are considered to be fully solved. At the same time, such tasks as text summarization or machine dialog systems are notoriously hard to crack and remain open for the past decades.},
}

@Article{PlavenSigray2017,
  author       = {Plavén-Sigray, Pontus and Matheson, Granville James and Schiffler, Björn Christian and Thompson, William Hedley},
  title        = {Research: The readability of scientific texts is decreasing over time},
  editor       = {King, Stuart},
  issn         = {2050-084X},
  pages        = {e27725},
  volume       = {6},
  abstract     = {Clarity and accuracy of reporting are fundamental to the scientific process. Readability formulas can estimate how difficult a text is to read. Here, in a corpus consisting of 709,577 abstracts published between 1881 and 2015 from 123 scientific journals, we show that the readability of science is steadily decreasing. Our analyses show that this trend is indicative of a growing use of general scientific jargon. These results are concerning for scientists and for the wider public, as they impact both the reproducibility and accessibility of research findings.},
  article_type = {journal},
  citation     = {eLife 2017;6:e27725},
  journal      = {eLife},
  keywords     = {metascience, readability, data analysis, jargon, scientific communication},
  pub_date     = {2017-09-05},
  publisher    = {eLife Sciences Publications, Ltd},
  year         = {2017},
}

@Article{Barnett2020,
  author       = {Barnett, Adrian and Doubleday, Zoe},
  title        = {Meta-Research: The growth of acronyms in the scientific literature},
  editor       = {Rodgers, Peter},
  issn         = {2050-084X},
  pages        = {e60080},
  volume       = {9},
  abstract     = {Some acronyms are useful and are widely understood, but many of the acronyms used in scientific papers hinder understanding and contribute to the increasing fragmentation of science. Here we report the results of an analysis of more than 24 million article titles and 18 million article abstracts published between 1950 and 2019. There was at least one acronym in 19\% of the titles and 73\% of the abstracts. Acronym use has also increased over time, but the re-use of acronyms has declined. We found that from more than one million unique acronyms in our data, just over 2,000 (0.2\%) were used regularly, and most acronyms (79\%) appeared fewer than 10 times. Acronyms are not the biggest current problem in science communication, but reducing their use is a simple change that would help readers and potentially increase the value of science.},
  article_type = {journal},
  citation     = {eLife 2020;9:e60080},
  journal      = {eLife},
  keywords     = {meta-research, scientific writing, acronyms, communication, knowledge, scientific publishing},
  pub_date     = {2020-07-23},
  publisher    = {eLife Sciences Publications, Ltd},
  year         = {2020},
}

@article{Gupta2019,
title = {Abstractive summarization: An overview of the state of the art},
journal = {Expert Systems with Applications},
volume = {121},
pages = {49-65},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2018.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0957417418307735},
author = {Som Gupta and S. K Gupta},
keywords = {Abstractive summarization, Concept finding, Semantic-Based summarization, Ontology-Based summarization, Deep learning},
abstract = {Summarization, is to reduce the size of the document while preserving the meaning, is one of the most researched areas among the Natural Language Processing (NLP) community. Summarization techniques, on the basis of whether the exact sentences are considered as they appear in the original text or new sentences are generated using natural language processing techniques, are categorized into extractive and abstractive techniques. Extractive summarization has been a very extensively researched topic and has reached to its maturity stage. Now the research has shifted towards the abstractive summarization. The complexities underlying with the natural language text makes abstractive summarization a difficult and a challenging task. This paper presents a comprehensive review of the various works performed in abstractive summarization field. For this purpose, we have selected the recent papers on this topic from Elsevier, ACM, IEEE, Springer, ACL Anthology, Cornell University Library and Google Scholar. The papers are categorized according to the type of abstractive technique used. The paper lists down the various challenges and discusses the future direction for research in this field. Along with these, we have identified the advantages and disadvantages of various methods used for abstractive summarization. We have also listed down the various tools which have been used or developed by researchers for abstractive summarization. The paper also discusses the evaluation techniques being used for assessing the abstractive summaries.}
}

@Online{Gupta2021,
  author = {Jyoti Gupta},
  date   = {2021-01-23},
  title  = {NLP Trends and Use Cases in 2021},
  url    = {https://www.whatech.com/og/artificial-intelligence/blog/688309-nlp-trends-and-use-cases-in-2021},
}

@Article{Donato2022,
  author   = {Donato, Antonella and Muscolo, Maria and Arias Romero, Mateo and Caprì, Tindara and Calarese, Tiziana and Olmedo Moreno, Eva María},
  title    = {Students with dyslexia between school and university: Post-diploma choices and the reasons that determine them. An Italian study},
  number   = {1},
  pages    = {110-127},
  volume   = {28},
  abstract = {Although the number of students with dyslexia enrolled in Italian universities is constantly growing, their presence remains relatively limited. The aim of this study was therefore to investigate the choices made by students with dyslexia in relation to university studies, and the underlying reasons for their choices. This study also compares these choices for students with and without dyslexia. In all, 440 high school students and their families agreed to take part in this project. Socio-demographic data was collected for the 47 students with dyslexia and 47 class-matched students without dyslexia, along with information on their current schools and their future educational plans. A specially developed questionnaire was used for the students, in combination with structured interviews with their families. The results show significant differences between these groups regarding both choices for university studies and the underlying motivations for these choices. Furthermore, certain psychological and emotional factors are implicated here in the decisions of the students with dyslexia regarding both university studies and their underlying reasons. Future research is needed to further investigate these factors in the educational choices of students with dyslexia.},
  journal  = {Dyslexia},
  keywords = {choices, dyslexia, reasons, students, university},
  year     = {2022},
}

@Article{VasquezRodriguez2021,
  author     = {Laura V{\'{a}}squez{-}Rodr{\'{\i}}guez and Matthew Shardlow and Piotr Przybyla and Sophia Ananiadou},
  title      = {Investigating Text Simplification Evaluation},
  eprint     = {2107.13662},
  eprinttype = {arXiv},
  volume     = {abs/2107.13662},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2107-13662.bib},
  journal    = {CoRR},
  timestamp  = {Tue, 03 Aug 2021 14:53:34 +0200},
  year       = {2021},
}

@InProceedings{Rello2012a,
  author    = {Rello, Luz and Kanvinde, Gaurang and Baeza-Yates, Ricardo},
  booktitle = {Proceedings of the International Cross-Disciplinary Conference on Web Accessibility},
  title     = {Layout Guidelines for Web Text and a Web Service to Improve Accessibility for Dyslexics},
  isbn      = {9781450310192},
  location  = {Lyon, France},
  publisher = {Association for Computing Machinery},
  series    = {W4A '12},
  abstract  = {In this paper, we offer set of guidelines and a web service that presents Web texts in a more more accessible way to people with dyslexia. The layout guidelines for developing this service are based on a user study with a group of twenty two dyslexic users. The data collected from our study combines qualitative data from interviews and questionnaires and quantitative data from tests carried out using eye tracking. We analyze and compare both kinds of data and present a set of layout guidelines for making the text Web more readable for dyslexic users. To the best of our knowledge, our methodology for defining dyslexic-friendly guidelines and our web service are novel.},
  address   = {New York, NY, USA},
  articleno = {36},
  keywords  = {browsing web service, web accessibility, dyslexia, readability, accessibility guidelines, usability tests},
  numpages  = {9},
  year      = {2012},
}

@Online{Readable2021,
  author = {Readable},
  date   = {2021},
  title  = {Flesch Reading Ease and the Flesch Kincaid Grade Level},
  url    = {https://readable.com/readability/flesch-reading-ease-flesch-kincaid-grade-level/},
}

@inproceedings{Gooding2022,
    title = "On the Ethical Considerations of Text Simplification",
    author = "Gooding, Sian",
    booktitle = "Ninth Workshop on Speech and Language Processing for Assistive Technologies (SLPAT-2022)",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.slpat-1.7",
    doi = "10.18653/v1/2022.slpat-1.7",
    pages = "50--57",
    abstract = "This paper outlines the ethical implications of text simplification within the framework of assistive systems. We argue that a distinction should be made between the technologies that perform text simplification and the realisation of these in assistive technologies. When using the latter as a motivation for research, it is important that the subsequent ethical implications be carefully considered. We provide guidelines for the framing of text simplification independently of assistive systems, as well as suggesting directions for future research and discussion based on the concerns raised.",
}

@Online{Miszczak2022,
  author = {Patryk Miszczak},
  date   = {2022-09-20},
  title  = {Natural Language Processing Statistics (2022)},
  url    = {https://businessolution.org/natural-language-processing-statistics/},
}

@article{Khyani2021,
    author = {Khyani, Divya and B S, Siddhartha},
    year = {2021},
    pages = {350-357},
    title = {An Interpretation of Lemmatization and Stemming in Natural Language Processing},
    volume = {22},
    journal = {Shanghai Ligong Daxue Xuebao/Journal of University of Shanghai for Science and Technology}
}

@Online{Droogenbroeck2022,
  author = {Kelly Van Droogenbroeck},
  date   = {2022-11-23},
  title  = {Scholen krijgen meer steun om leerlingen met beperking op te vangen},
  url    = {https://www.demorgen.be/snelnieuws/scholen-krijgen-meer-steun-om-leerlingen-met-beperking-op-te-vangen~bb2469df/},
}

@InProceedings{Garbacea2021,
  author    = {Garbacea, Cristina and Guo, Mengtian and Carton, Samuel and Mei, Qiaozhu},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  title     = {Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification},
  doi       = {10.18653/v1/2021.acl-long.88},
  pages     = {1086--1097},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.88},
  abstract  = {Text simplification reduces the language complexity of professional content for accessibility purposes. End-to-end neural network models have been widely adopted to directly generate the simplified version of input text, usually functioning as a blackbox. We show that text simplification can be decomposed into a compact pipeline of tasks to ensure the transparency and explainability of the process. The first two steps in this pipeline are often neglected: 1) to predict whether a given piece of text needs to be simplified, and 2) if yes, to identify complex parts of the text. The two tasks can be solved separately using either lexical or deep learning methods, or solved jointly. Simply applying explainable complexity prediction as a preliminary step, the out-of-sample text simplification performance of the state-of-the-art, black-box simplification models can be improved by a large margin.},
  address   = {Online},
  year      = {2021},
}

@Article{Bulte2018,
  author       = {Bulté, Bram and Sevens, Leen and Vandeghinste, Vincent},
  title        = {Automating lexical simplification in Dutch},
  pages        = {24–48},
  url          = {https://clinjournal.org/clinj/article/view/78},
  volume       = {8},
  abstractnote = {&amp;lt;p&amp;gt;We discuss the design, development and evaluation of an automated lexical simplification tool for Dutch. A basic pipeline approach is used to perform both text adaptation and annotation. First, sentences are preprocessed and word sense disambiguation is performed. Then, the difficulty of each token is estimated by looking at their average age of acquisition and frequency in a corpus of simplified Dutch. We use Cornetto to find synonyms of words that have been identified as difficult and the SONAR500 corpus to perform reverse lemmatisation. Finally, we rely on a largescale language model to verify whether the selected replacement word fits the local context. In addition, the text is augmented with information from Wikipedia (word definitions and links). We tune and evaluate the system with sentences taken from the Flemish newspaper De Standaard. The results show that the system’s adaptation component has low coverage, since it only correctly simplifies around one in five ‘difficult’ words, but reasonable accuracy, with no grammatical errors being introduced in the text. The Wikipedia annotations have a broader coverage, but their potential for simplification needs to be further developed and more thoroughly evaluated.&amp;lt;/p&amp;gt;},
  journal      = {Computational Linguistics in the Netherlands Journal},
  year         = {2018},
}

@Online{Verhoeven2023,
  author = {Wim Verhoeven},
  date   = {2023-02-08},
  editor = {Trends},
  title  = {Applaus voor de studenten die ChatGPT gebruiken},
  url    = {https://trends.knack.be/economie/bedrijven/applaus-voor-de-studenten-die-chatgpt-gebruiken/article-opinion-1934277.html?cookie_check=1676034368},
}

@Online{Malik2022,
  author = {Rijul Sing Malik},
  date   = {2022-07-04},
  editor = {Towards AI},
  title  = {Top 5 NLP Libraries To Use in Your Projects},
  url    = {https://towardsai.net/p/l/top-5-nlp-libraries-to-use-in-your-projects},
}

@Article{Shardlow2014,
  author    = {Matthew Shardlow},
  title     = {A Survey of Automated Text Simplification},
  doi       = {10.14569/SpecialIssue.2014.040109},
  number    = {1},
  url       = {http://dx.doi.org/10.14569/SpecialIssue.2014.040109},
  volume    = {4},
  journal   = {International Journal of Advanced Computer Science and Applications(IJACSA), Special Issue on Natural Language Processing 2014},
  publisher = {The Science and Information Organization},
  year      = {2014},
}

@Article{Thangarajah2019,
  author = {Thangarajah, Vinothraj},
  title  = {Python current trend applications-an overview},
  year   = {2019},
}

@InProceedings{Iavarone2021,
  author    = {Iavarone, Benedetta and Brunato, Dominique and Dell{'}Orletta, Felice},
  booktitle = {Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},
  title     = {Sentence Complexity in Context},
  doi       = {10.18653/v1/2021.cmcl-1.23},
  pages     = {186--199},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.cmcl-1.23},
  abstract  = {We study the influence of context on how humans evaluate the complexity of a sentence in English. We collect a new dataset of sentences, where each sentence is rated for perceived complexity within different contextual windows. We carry out an in-depth analysis to detect which linguistic features correlate more with complexity judgments and with the degree of agreement among annotators. We train several regression models, using either explicit linguistic features or contextualized word embeddings, to predict the mean complexity values assigned to sentences in the different contextual windows, as well as their standard deviation. Results show that models leveraging explicit features capturing morphosyntactic and syntactic phenomena perform always better, especially when they have access to features extracted from all contextual sentences.},
  address   = {Online},
  year      = {2021},
}

@Book{Sohom2019,
  author    = {Sohom, Ghosh; Dwight, Gunning},
  date      = {2019},
  title     = {Natural Language Processing Fundamentals},
  isbn      = {9781789954043},
  language  = {English},
  publisher = {Packt Publishing},
  url       = {https://medium.com/analytics-vidhya/natural-language-processing-basic-concepts-a3c7f50bf5d3},
  abstract  = {Use Python and NLTK (Natural Language Toolkit) to build out your own text classifiers and solve common NLP problems. Key Features Assimilate key NLP concepts and terminologies Explore popular NLP tools and techniques Gain practical experience using NLP in application code Book Description If NLP hasn't been your forte, Natural Language Processing Fundamentals will make sure you set off to a steady start. This comprehensive guide will show you how to effectively use Python libraries and NLP concepts to solve various problems. You'll be introduced to natural language processing and its applications through examples and exercises. This will be followed by an introduction to the initial stages of solving a problem, which includes problem definition, getting text data, and preparing it for modeling. With exposure to concepts like advanced natural language processing algorithms and visualization techniques, you'll learn how to create applications that can extract information from unstructured data and present it as impactful visuals. Although you will continue to learn NLP-based techniques, the focus will gradually shift to developing useful applications. In these sections, you'll understand how to apply NLP techniques to answer questions as can be used in chatbots. By the end of this book, you'll be able to accomplish a varied range of assignments ranging from identifying the most suitable type of NLP task for solving a problem to using a tool like spacy or gensim for performing sentiment analysis. The book will easily equip you with the knowledge you need to build applications that interpret human language. What you will learn Obtain, verify, and clean data before transforming it into a correct format for use Perform data analysis and machine learning tasks using Python Understand the basics of computational linguistics Build models for general natural language processing tasks Evaluate the performance of a model with the right metrics Visualize, quantify, and perform exploratory analysis from any text data Who this book is for Natural Language Processing Fundamentals is designed for novice and mid-level data scientists and machine learning developers who want to gather and analyze text data to build an NLP-powered product. It'll help you to have prior experience of coding in Python using data types, writing functions, and importing libraries. Some experience with linguistics and probability is useful but not necessary.},
}

@Conference{DeBelder2010,
  author    = {De Belder, Jan; Moens, Marie-Francine},
  date      = {2010},
  title     = {Text simplification for children},
  language  = {eng},
  publisher = {ACM; New York},
  abstract  = {The goal in this paper is to automatically transform text into a simpler text, so that it is easier to understand by children. We perform syntactic simplification, i.e. the splitting of sentences, and lexical simplification, i.e. replacing difficult words with easier synonyms. We test the performance of this approach for each component separately on a per sentence basis, and globally with the automatic construction of simplified news articles and encyclopedia articles. By including information from a language model in the lexical simplification step, we obtain better results over a baseline method. The syntactic simplification shows that some phenomena are hard to recognize by a parser, and that errors are often introduced. Although the reading difficulty goes down, it still doesn’t reach the required level needed for young children.},
  journal   = {Prroceedings of the SIGIR workshop on accessible search systems},
  keywords  = {Text simplification},
  year      = {2010},
}

@Article{Siddharthan2006,
  author    = {Advaith Siddharthan},
  title     = {Syntactic Simplification and Text Cohesion},
  number    = {1},
  pages     = {77--109},
  url       = {http://oro.open.ac.uk/58888/},
  volume    = {4},
  abstract  = {Syntactic simplification is the process of reducing the grammatical complexity of a text, while retaining its information content and meaning. The aim of syntactic simplification is to make text easier to comprehend for human readers, or process by programs. In this paper, we formalise the interactions that take place between syntax and discourse during the simplification process. This is important because the usefulness of syntactic simplification in making a text accessible to a wider audience can be undermined if the rewritten text lacks cohesion. We describe how various generation issues like sentence ordering, cue-word selection, referring-expression generation, determiner choice and pronominal use can be resolved so as to preserve conjunctive and anaphoric cohesive relations during syntactic simplification and present the results of an evaluation of our syntactic simplification system.},
  journal   = {Research on Language and Computation},
  keywords  = {anaphoric structure; cue-word selection; determiner choice; discourse structure; sentence ordering; syntactic simplification; text cohesion},
  publisher = {Springer Netherlands},
  year      = {2006},
}

@Online{Dapaah2022,
  author = {Dapaah, Josephine and Maenhout, Klaas},
  date   = {2022-07-08},
  editor = {De Standaard},
  title  = {Iedereen heeft boter op zijn hoofd},
  url    = {https://www.standaard.be/cnt/dmf20220607_97763592},
}

@Article{Wafaa2021,
title = {Automatic text summarization: A comprehensive survey},
journal = {Expert Systems with Applications},
volume = {165},
pages = {113679},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113679},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420305030},
author = {Wafaa S. El-Kassas and Cherif R. Salama and Ahmed A. Rafea and Hoda K. Mohamed},
keywords = {Automatic text summarization, Text summarization approaches, Text summarization techniques, Text summarization evaluation},
abstract = {Automatic Text Summarization (ATS) is becoming much more important because of the huge amount of textual content that grows exponentially on the Internet and the various archives of news articles, scientific papers, legal documents, etc. Manual text summarization consumes a lot of time, effort, cost, and even becomes impractical with the gigantic amount of textual content. Researchers have been trying to improve ATS techniques since the 1950s. ATS approaches are either extractive, abstractive, or hybrid. The extractive approach selects the most important sentences in the input document(s) then concatenates them to form the summary. The abstractive approach represents the input document(s) in an intermediate representation then generates the summary with sentences that are different than the original sentences. The hybrid approach combines both the extractive and abstractive approaches. Despite all the proposed methods, the generated summaries are still far away from the human-generated summaries. Most researches focus on the extractive approach. It is required to focus more on the abstractive and hybrid approaches. This research provides a comprehensive survey for the researchers by presenting the different aspects of ATS: approaches, methods, building blocks, techniques, datasets, evaluation methods, and future research directions.}
}

@Article{Niemeijer2010,
title = "Ethical and practical concerns of surveillance technologies in residential care for people with dementia or intellectual disabilities: an overview of the literature",
author = "A.R. Niemeijer and B.J.M. Frederiks and II Riphagen and J. Legemaate and J.A. Eefsting and C.M.P.M. Hertogh",
year = "2010",
doi = "10.1017/S1041610210000037",
language = "Undefined/Unknown",
volume = "22",
pages = "1129--1142",
journal = "Psychogeriatrics",
issn = "1041-6102",
publisher = "Cambridge University Press",
number = "7",
}

@article{Punardeep2020,
  author    = {Punardeep Sikka and
               Vijay Mago},
  title     = {A Survey on Text Simplification},
  journal   = {CoRR},
  volume    = {abs/2008.08612},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.08612},
  eprinttype = {arXiv},
  eprint    = {2008.08612},
  timestamp = {Fri, 28 Aug 2020 09:01:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-08612.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Xu2015,
  title={Problems in current text simplification research: New data can help},
  author={Xu, Wei and Callison-Burch, Chris and Napoles, Courtney},
  journal={Transactions of the Association for Computational Linguistics},
  volume={3},
  pages={283--297},
  year={2015},
  publisher={MIT Press}
}

@InProceedings{Canning2000,
author="Canning, Yvonne
and Tait, John
and Archibald, Jackie
and Crawley, Ros",
editor="Sojka, Petr
and Kope{\v{c}}ek, Ivan
and Pala, Karel",
title="Cohesive Generation of Syntactically Simplified Newspaper Text",
booktitle="Text, Speech and Dialogue",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="145--150",
abstract="This paper describes SYSTAR (SYntactic Simplification of Text for Aphasic Readers), the PSet module which splits compound sentences, activises seven agentive passive clause types, and resolves and replaces eight frequently occurring anaphoric pronouns. We describe our techniques and strategies, report on the results obtained after evaluation of a corpus of 100 newspaper articles downloaded from the website of a daily provincial, and briefly report on experimental studies with aphasic participants.",
isbn="978-3-540-45323-9"
}

@inproceedings{Coster2011,
    title = "Learning to Simplify Sentences Using {W}ikipedia",
    author = "Coster, Will  and
      Kauchak, David",
    booktitle = "Proceedings of the Workshop on Monolingual Text-To-Text Generation",
    year = "2011",
    address = "Portland, Oregon",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W11-1601",
    pages = "1--9",
}


@inproceedings{Kandula2010,
  title={A semantic and syntactic text simplification tool for health content},
  author={Kandula, Sasikiran and Curtis, Dorothy and Zeng-Treitler, Qing},
  booktitle={AMIA annual symposium proceedings},
  volume={2010},
  pages={366},
  year={2010},
  organization={American Medical Informatics Association}
}

@misc{Vandeghinste2019,
abstract = {This paper presents the Wablieft corpus, a two million words corpus of a Belgian easy-to-read newspaper, written in Dutch. The corpus was automatically annotated with CLARIN tools and is made available in several formats for download and online querying, through the CLARIN infrastructure. Annotations consist of part-of-speech tagging, chunking, dependency parsing, named entity recognition, morphological analysis and universal dependencies. By making this corpus available we want to stimulate research into text readability and automated text simplification.},
author = {Vandeghinste, Vincent and Bulté, Bram and Augustinus, Liesbeth},
journal = {Proceedings of CLARIN Annual Conference 2019},
publisher = {CLARIN},
title = {Wablieft: An Easy-to-Read Newspaper Corpus for Dutch},
year = {2019},
}

@inproceedings{Poel2008,
title = "A Neural Network Based Dutch Part of Speech Tagger",
keywords = "IR-65237, METIS-255028, EWI-14662",
author = "Mannes Poel and Egwin Boschman and {op den Akker}, Rieks",
note = "http://eprints.ewi.utwente.nl/14662 ; 20th Benelux Conference on Artificial Intelligence, BNAIC 2008, BNAIC ; Conference date: 30-10-2008 Through 31-10-2008",
year = "2008",
language = "English",
series = "BNAIC: proceedings of the ... Belgium/Netherlands Artificial Intelligence Conference",
publisher = "Twente University Press (TUP)",
number = "20",
pages = "217--224",
editor = "Anton Nijholt and Maja Pantic and Mannes Poel and Hendri Hondorp",
booktitle = "BNAIC 2008",
address = "Netherlands",
}


@book{Eisenstein2019,
  title={Introduction to Natural Language Processing},
  author={Eisenstein, J.},
  isbn={9780262042840},
  lccn={2018059552},
  series={Adaptive Computation and Machine Learning series},
  url={https://books.google.be/books?id=72yuDwAAQBAJ},
  year={2019},
  publisher={MIT Press}
}


@inproceedings{Schovilet2017,
author = {Scholivet, Manon and Ramisch, Carlos},
year = {2017},
pages = {167-175},
title = {Identification of Ambiguous Multiword Expressions Using Sequence Models and Lexical Resources},
doi = {10.18653/v1/W17-1723}
}

@InProceedings{Zeng2005,
    author={Zeng, Qing and Kim, Eunjung and Crowell, Jon and Tse, Tony},
    editor={"Oliveira, Jos{\'e} Lu{\'i}s and Maojo, V{\'i}ctor and Mart{\'i}n-S{\'a}nchez, Fernando and Pereira, Ant{\'o}nio Sousa"},
    title="A Text Corpora-Based Estimation of the Familiarity of Health Terminology",
    booktitle="Biological and Medical Data Analysis",
    year="2005",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="184--192",
    abstract="In a pilot effort to improve health communication we created a method for measuring the familiarity of various medical terms. To obtain term familiarity data, we recruited 21 volunteers who agreed to take medical  terminology quizzes containing 68 terms. We then created predictive models for familiarity based on term occurrence in text corpora and reader's demographics. Although the sample size was small, our preliminary results indicate that predicting the familiarity of medical terms based on an analysis of the frequency in text corpora is feasible. Further, individualized familiarity assessment is feasible when demographic features are included as predictors.",
    isbn="978-3-540-31658-9"
}


@article{Lissens2020,
author = {Lissens, Femke and Asmar, Masarrat and Willems, Daniëlle and Van Damme, Jana and De Coster, Sandrine and Demeestere, Emma and Maes, Romy and Baccarne, Bastiaan and Robaeyst, Ben and Duthoo, Wout and Desoete, Annemie},
year = {2020},
title = {Het stopt nooit…De impact van dyslexie en/of dyscalculie op het welbevinden en studeren van (jong)volwassenen en op de transitie naar de arbeidsmarkt: een bundeling van Vlaamse pilootstudies.}
}

@book{Ghesquiere2018,
  title     = "Als leren pijn doet: Kinderen met een leerstoornis opvoeden en begeleiden",
  author    = "Ghesquière, Pol",
  year      = 2018,
  publisher = "Acco",
}

@Article{Vasista2022,
  author       = {Vasista, Kola},
  title        = {Evolution of AI Design Models},
  number       = {3},
  pages        = {1-4},
  volume       = {3},
  abstractnote = {&lt;p&gt;Today, the articulation expert system, and even merely artificial intelligence, is generally and also ordinarily utilized to describe any kind of machine learning training course. Inside, it is beginning to replace &quot;large records&quot; and its very own hangers-on, &quot;sped up analytics&quot; and also &quot;predictive analytics. For those that do not like the phrase &quot;big files,&quot; this is likely an excellent idea. This paper provides business/technology trends, design models, benefits and approaches towards artificlial intellingence. This paper provides the evolution of AI Design models.&lt;/p&#38;gt;},
  journal      = {Central Asian Journal of Theoretical and Applied Science},
  year         = {2022},
}


@inproceedings{Suter2016,
author = {Suter, Julia and Ebling, Sarah and Volk, Martin},
year = {2016},
title = {Rule-based Automatic Text Simplification for German}
}

@Online{Deckmyn2021,
  author = {Dominique Deckmyn},
  date   = {2021-03-19},
  editor = {De Standaard},
  title  = {Robot schrijft mee De Standaard},
  url    = {https://www.standaard.be/cnt/dmf20210319_05008561},
}

@article{Hahn2000,
author = {Hahn, Udo and Mani, Inderjeet},
year = {2000},
pages = {29-36},
title = {The Challenges of Automatic Summarization},
volume = {33},
journal = {Computer},
doi = {10.1109/2.881692}
}

@article{McKeown1999,
  title={Towards multidocument summarization by reformulation: Progress and prospects},
  author={McKeown, Kathleen and Klavans, Judith L and Hatzivassiloglou, Vasileios and Barzilay, Regina and Eskin, Eleazar},
  year={1999}
}

@inproceedings{Zhang2020,
  title={Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  booktitle={International Conference on Machine Learning},
  pages={11328--11339},
  year={2020},
  organization={PMLR}
}

@article{Nallapati2017, 
    title={SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents}, 
    volume={31}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/10958}, 
    DOI={10.1609/aaai.v31i1.10958},      
    abstractNote={ &lt;p&gt; We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence model for extractive summarization of documents and show that it achieves performance better than or comparable to state-of-the-art. Our model has the additional advantage of being very interpretable, since it allows visualization of its predictions broken up by abstract features such as information content, salience and novelty. Another novel contribution of our work is abstractive training of our extractive model that can train on human generated reference summaries alone, eliminating the need for sentence-level extractive labels. &lt;/p&gt; }, 
    number={1}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Nallapati, Ramesh and Zhai, Feifei and Zhou, Bowen}, 
    year={2017} 
}

@misc{Xiao2019,
  author = {Xiao, Wen and Carenini, Giuseppe},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Extractive Summarization of Long Documents by Combining Global and Local Context},
  publisher = {arXiv},
  year = {2019},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Bilisci2021, title={Sequence labeling}, journal={Medium}, publisher={Artiwise NLP}, author={Bilici, Şafak}, year={2021}} 

@book{Jurafsky2014,
  title={Speech and Language Processing},
  author={Jurafsky, D. and Martin, J.H. and Norvig, P. and Russell, S.},
  isbn={9780133252934},
  url={https://books.google.be/books?id=Cq2gBwAAQBAJ},
  year={2014},
  publisher={Pearson Education}
}

@misc{Li2018,
  author = {Li, Jing and Sun, Aixin and Han, Jianglei and Li, Chenliang},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey on Deep Learning for Named Entity Recognition},
  publisher = {arXiv},
  year = {2018},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Dubay2004,
  title={The principles of readability.},
  author={DuBay, William H},
  journal={Online Submission},
  year={2004},
  publisher={ERIC}
}

@inproceedings{Carbonell1998,
  title={The use of MMR, diversity-based reranking for reordering documents and producing summaries},
  author={Carbonell, Jaime and Goldstein, Jade},
  booktitle={Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={335--336},
  year={1998}
}

@misc{Grootendorst2022,
  author = {Grootendorst, Maarten},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Lin2010,
  title={Multi-document summarization via budgeted maximization of submodular functions},
  author={Lin, Hui and Bilmes, Jeff},
  booktitle={Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={912--920},
  year={2010}
}

@inproceedings{McDonald2007,
  title={A study of global inference algorithms in multi-document summarization},
  author={McDonald, Ryan},
  booktitle={Advances in Information Retrieval: 29th European Conference on IR Research, ECIR 2007, Rome, Italy, April 2-5, 2007. Proceedings 29},
  pages={557--564},
  year={2007},
  organization={Springer}
}

@article{Verma2020,
  title={A review on text summarization techniques},
  author={Verma, Pradeepika and Verma, Anshul},
  journal={Journal of scientific research},
  volume={64},
  number={1},
  pages={251--257},
  year={2020}
}

@article{Khan2014,
    author = {Khan, Atif},
    year = {2014},
    pages = {64-72},
    title = {A Review on Abstractive Summarization Methods},
    volume = {59},
    journal = {Journal of Theoretical and Applied Information Technology}
}

@article{Hubbard2017,
    author = {Hubbard, Katharine E. AND Dunbar, Sonja D.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Perceptions of scientific research literature and strategies for reading papers depend on academic career stage},
    year = {2017},
    volume = {12},
    pages = {1-16},
    abstract = {Reading primary research literature is an essential skill for all scientists and students on science degree programmes, however little is known about how researchers at different career stages interact with and interpret scientific papers. To explore this, we conducted a survey of 260 undergraduate students and researchers in Biological Sciences at a research intensive UK university. Responses to Likert scale questions demonstrated increases in confidence and skill with reading the literature between individuals at each career stage, including between postdoctoral researchers and faculty academics. The survey indicated that individuals at different career stages valued different sections of scientific papers, and skill in reading the results section develops slowly over the course of an academic career. Inexperienced readers found the methods and results sections of research papers the most difficult to read, and undervalued the importance of the results section and critical interpretation of data. These data highlight a need for structured support with reading scientific literature at multiple career stages, and for senior academics to be aware that junior colleagues may prioritise their reading differently. We propose a model for the development of literature processing skills, and consider the need for training strategies to help inexperienced readers engage with primary literature, and therefore develop important skills that underpin scientific careers. We also encourage researchers to be mindful of language used when writing papers, and to be more inclusive of diverse audiences when disseminating their work.},
    number = {12},
}

 @misc{Filipak2020, 
    title={Leesproblemen en Dyslexie: Leesproblemen -2-}, 
    url={https://wij-leren.nl/leesproblemen-dyslexie-woordbenoeming-woordherkenning-begripsprobleem-deel-twee.php#_edn11}, 
    journal={Wij leren}, 
    publisher={Wij leren}, 
    author={Filipiak, Paul}, 
    year={2020}
} 


@Article{AbdelSalam2022,
    author = {Abdel-Salam, Shehab and Rafea, Ahmed},
    title = {Performance Study on Extractive Text Summarization Using BERT Models},
    journal = {Information},
    YEAR = {2022},
    number = {2},
}

@article{Rani2021,
  title={The TEXT SUMMARIZATION AND ITS EVALUATION TECHNIQUE},
  author={Rani, Rimpi and Kaur, Baljinder},
  journal={Turkish Journal of Computer and Mathematics Education (TURCOMAT)},
  volume={12},
  number={1},
  pages={745--752},
  year={2021}
}


@inproceedings{Premjith2015,
author = {Premjith, P. and John, Ansamma and Wilscy, M.},
year = {2015},
pages = {347-358},
title = {Metaheuristic Optimization Using Sentence Level Semantics for Extractive Document Summarization},
isbn = {978-3-319-26831-6},
doi = {10.1007/978-3-319-26832-3_33}
}

@inproceedings{Parveen2015,
  title={Integrating importance, non-redundancy and coherence in graph-based extractive summarization},
  author={Parveen, Daraksha and Strube, Michael},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}

@misc{Cao2022,
  author = {Cao, Meng},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey on Neural Abstractive Summarization Methods and Factual Consistency of Summarization},
  publisher = {arXiv},
  year = {2022}
}

@article{Wentink2008,
    author = {Wentink, W. and Verhoeven, Ludo and Druenen, M.},
    year = {2008},
    pages = {},
    title = {Protocol leesproblemen en dyslexie voor groep 1 en 2},
    journal = {Clinical Rheumatology - CLIN RHEUMATOL}
}

@article{Desoete2017,
  author       = {Desoete, Annemie},
  issn         = {{1782-2211}},
  journal      = {{SPRANKEL}},
  language     = {{dut}},
  number       = {{2}},
  pages        = {{17--31}},
  title        = {{Dyslexie of dyscalculie, niet de schuld van het onderwijs! En een correcte diagnose schaadt niet}},
  volume       = {{28}},
  year         = {{2017}},
}

@book{APA2013,
  title={Diagnostic and statistical manual of mental disorders: DSM-5},
  author={American Psychiatric Association},
  volume={5},
  number={5},
  year={2013},
  publisher={American psychiatric association Washington, DC}
}


@book{Surma2019,
title = "Wijze lessen: twaalf bouwstenen voor effectieve didactiek",
abstract = "Dagelijks verzorgen duizenden leraren in het onderwijs duizenden urenles. Hoewel het takenpakket van leraren zeer divers is, is het verzorgenvan een goede les een van de kerntaken van de leraar. Lesgeven is de corebusiness van het leraarschap. Daarom beschrijven we in dit boek twaalfdidactische bouwstenen die leraren kunnen gebruiken om hun lesseneffectiever te maken. Leraren zullen merken dat je in dit boek geen {\textquoteleft}rocketscience{\textquoteright} zult aantreffen, maar wel heldere, duidelijke en wetenschappelijkonderbouwde bouwstenen die hen raken in de kern van het vak, namelijkhet lesgeven gericht op langetermijnleren. ",
author = "T Surma and Kristel Vanhoyweghen and Dominique Sluijsmans and G. Camp and Dani{\"e}l Muijs and P.A. Kirschner",
year = "2019",
day = "16",
language = "Dutch",
isbn = "9789077866528",
publisher = "Ten Brink Uitgevers",
address = "Netherlands",
edition = "1",
}


@article{Ball2017,
author = {Ball, Philip},
year = {2017},
title = {It's not just you: science papers are getting harder to read},
journal = {Nature}
}


 @misc{Pain2016, 
    title={How to (seriously) read a scientific paper}, 
    url={https://www.science.org/content/article/how-seriously-read-scientific-paper}, 
    journal={Science}, 
    author={Pain, Elisabeth}, 
    year={2016}
} 


@article{Dronberger1975,
  title={Abstract readability as a factor in information systems},
  author={Dronberger, Gladys B and Kowitz, Gerald T},
  journal={Journal of the American Society for Information Science},
  volume={26},
  number={2},
  pages={108--111},
  year={1975},
  publisher={Wiley Online Library}
}


@misc{Hayes1992, 
    title={The growing inaccessibility of science}, 
    url={https://www.nature.com/articles/356739a0}, 
    journal={Nature News}, 
    publisher={Nature Publishing Group}, 
    author={Hayes, Donald P.}, 
    year={1992}
} 


@inproceedings{Jones2019,
author = {Jones, Ridley and Colusso, Lucas and Reinecke, Katharina and Hsieh, Gary},
year = {2019},
pages = {1-14},
title = {r/science: Challenges and Opportunities in Online Science Communication},
isbn = {978-1-4503-5970-2},
journal = {CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3290605.3300383}
}


@misc{Glorieux2018, 
    title={De arbeidsduur en werkcontext van leraren. Onderzoek naar de tijdsbesteding van leraren uit het basis- en secundair onderwijs.}, 
    url={https://torvub.be/wp-content/uploads/2018/09/Samenvatting.pdf}, 
    journal={TORVUB},  
    publisher={Onderzoeksgroep TOR - Vrije Universiteit Brussel}, 
    author={Minnen, Joeri and Verbeylen, Julie and Glorieux, Ignace}, 
    year={2018}
} 

@misc{Ruben2016, 
    title={How to read a scientific paper}, 
    url={https://www.science.org/content/article/how-read-scientific-paper-rev2}, 
    journal={Science}, 
    publisher={Science}, 
    author={Ruben, Adam}, 
    year={2016}
} 

@misc{DeMeyer2019, title={Leesvaardigheid van 15- jarigen in Vlaanderen: Overzicht van de eerste resultaten van PISA2018}, url={https://data-onderwijs.vlaanderen.be/documenten/bestand.ashx?id=12265}, journal={Data Onderwijs Vlaanderen}, publisher={Universiteit Gent}, author={De Meyer, Inge and Janssens, Ruth and Warlop, Nele}, year={2019}} 


@article{Ennals2010,
author = {F, Manjoo and Ennals, Richard},
year = {2010},
pages = {180-180},
title = {True Enough: Learning to Live in a Post-Fact Society , John Wiley, New Jersey (2008)},
volume = {30},
journal = {International Journal of Information Management - INT J INFORM MANAGE},
}

@article{Hartley1994,
author = {Hartley, James},
title = {Three ways to improve the clarity of journal abstracts},
journal = {British Journal of Educational Psychology},
volume = {64},
number = {2},
pages = {331-343},
url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8279.1994.tb01106.x},
eprint = {https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8279.1994.tb01106.x},
abstract = {Fourteen abstracts, taken from a recent issue of the British Journal of Educational Psychology, were printed in four different versions. Version 1 was the original format. Version 2 matched Version 1, but its type-size was increased to that of the corresponding article. Version 3 matched Version 2, but paragraphs were introduced to clarify the underlying structure. Version 4 matched Version 3, but the text of the abstract was rewritten in an attempt to clarify the text even further. The effects of these changes were assessed in four ways. Firstly, undergraduates each ranked for clarity Versions 1–4 of individual abstracts. The results showed that each change in design lead to a significantly greater preference - thus Version 1 was the least preferred and Version 4 the most preferred. Secondly, Flesch readability scores were computed for the original and the revised abstracts. It was shown using this measure that the revised abstracts were significantly easier to read than the originals. Thirdly, academic staff and postgraduates completed cloze (comprehension) tests on original and revised versions of two of the original abstracts. The results showed (i) significantly higher cloze test scores for the revised versions, and (ii) that experienced staff and postgraduates performed significantly better on both versions than did beginning postgraduate students. Finally British and overseas postgraduate students of librarianship completed a cloze version of an original and its revised abstract. The results showed that the British students did significantly better than overseas ones, and that both groups scored significantly higher on the revised abstract. These four sets of data thus indicate that it is possible to improve the clarity of journal abstracts, and that this can be achieved for many different kinds of reader.},
year = {1994}
}


@article{Hartley1999,
author = {James Hartley},
title ={From Structured Abstracts to Structured Articles: A Modest Proposal},
journal = {Journal of Technical Writing and Communication},
volume = {29},
number = {3},
pages = {255-270},
year = {1999},
doi = {10.2190/3RWW-A579-HC8W-6866},
abstract = { Work with structured abstracts—which contain sub-headings in a standard order—has suggested that such abstracts contain more information, are of a higher quality, and are easier to search and to read than are traditional abstracts. The aim of this article is to suggest that this work with structured abstracts can be extended to cover scientific articles as a whole. The article outlines a set of sub-headings—drawn from research on academic writing—that can be used to make the presentation of scientific papers easier to read and to write. Twenty published research papers are then analyzed in terms of these sub-headings. The analysis, with some reservations, supports the viability of this approach. }
}

@article{Wang2022,
author = {Wang, Shan and Liu, Xiaojun and Zhou, Jie},
title = {Readability is Decreasing in Language and Linguistics},
year = {2022},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {127},
number = {8},
issn = {0138-9130},
abstract = {Readability reflects the ease of reading a text and high readability indicates easy texts. Based on a corpus consisting of 71,628 abstracts published in SSCI journals in language and linguistics from 1991 to 2020, this paper employs nine readability indexes to analyze their readability and relationship with citations. The results show that the readability of abstracts in journals of language and linguistics is low. Moreover, in the past 30&nbsp;years, the abstract readability in language and linguistics abstracts is decreasing. Meanwhile, readability is significantly negatively correlated with the number of citations, even though the effect size is very small. The results above suggest that abstracts are very difficult to read; they are becoming more and more difficult than before; the abstract of the articles with more citations appear to be less readable. Faced with decreasing readability, it is suggested that scholars make themselves understood when expressing their ideas with jargon. This study not only has implications for scholars to use linguistic features to improve readability, but also provides quantitative support for the research on readability.},
journal = {Scientometrics},
pages = {4697–4729},
numpages = {33},
keywords = {Readability, Language, Linguistics, Citation, Abstracts}
}

@article{McNutt2014,
author = {Marcia McNutt },
title = {Reproducibility},
journal = {Science},
volume = {343},
number = {6168},
pages = {229-229},
year = {2014},
doi = {10.1126/science.1250475},
URL = {https://www.science.org/doi/abs/10.1126/science.1250475},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1250475},
abstract = {Science advances on a foundation of trusted discoveries. Reproducing an experiment is one important approach that scientists use to gain confidence in their conclusions. Recently, the scientific community was shaken by reports that a troubling proportion of peer-reviewed preclinical studies are not reproducible. Because confidence in results is of paramount importance to the broad scientific community, we are announcing new initiatives to increase confidence in the studies published in Science. For preclinical studies (one of the targets of recent concern), we will be adopting recommendations of the U.S. National Institute of Neurological Disorders and Stroke (NINDS) for increasing transparency.* Authors will indicate whether there was a pre-experimental plan for data handling (such as how to deal with outliers), whether they conducted a sample size estimation to ensure a sufficient signal-to-noise ratio, whether samples were treated randomly, and whether the experimenter was blind to the conduct of the experiment. These criteria will be included in our author guidelines.}}


@article{Hubbard2017,
    author = {Hubbard, Katharine E. AND Dunbar, Sonja D.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Perceptions of scientific research literature and strategies for reading papers depend on academic career stage},
    year = {2017},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0189753},
    pages = {1-16},
    abstract = {Reading primary research literature is an essential skill for all scientists and students on science degree programmes, however little is known about how researchers at different career stages interact with and interpret scientific papers. To explore this, we conducted a survey of 260 undergraduate students and researchers in Biological Sciences at a research intensive UK university. Responses to Likert scale questions demonstrated increases in confidence and skill with reading the literature between individuals at each career stage, including between postdoctoral researchers and faculty academics. The survey indicated that individuals at different career stages valued different sections of scientific papers, and skill in reading the results section develops slowly over the course of an academic career. Inexperienced readers found the methods and results sections of research papers the most difficult to read, and undervalued the importance of the results section and critical interpretation of data. These data highlight a need for structured support with reading scientific literature at multiple career stages, and for senior academics to be aware that junior colleagues may prioritise their reading differently. We propose a model for the development of literature processing skills, and consider the need for training strategies to help inexperienced readers engage with primary literature, and therefore develop important skills that underpin scientific careers. We also encourage researchers to be mindful of language used when writing papers, and to be more inclusive of diverse audiences when disseminating their work.},
    number = {12},
}

@article{Snow2010,
author = {Snow, Catherine},
year = {2010},
pages = {450-2},
title = {Academic Language and the Challenge of Reading for Learning About Science},
volume = {328},
journal = {Science (New York, N.Y.)}
}

@misc{Bezem2016, 
    title={Visuele Disfunctie een onzichtbare belemmering bij  lezen, spelling en concentratie.}, 
    url={https://beeldenbrein.nl/}, 
    journal={Beeld en Brein}, 
    publisher={Beeld en Brein}, 
    author={Bezem, Anneke and Lugthart, Marjon}, 
    year={2016}, 
} 

@article{Zhang2021,
title = {Neurophysiological tracking of speech-structure learning in typical and dyslexic readers},
journal = {Neuropsychologia},
volume = {158},
pages = {107889},
year = {2021},
issn = {0028-3932},
author = {Manli Zhang and Lars Riecke and Milene Bonte},
keywords = {Developmental dyslexia, Statistical learning, Word segmentation, Frequency-tagging, Neural plasticity},
abstract = {Statistical learning, or the ability to extract statistical regularities from the sensory environment, plays a critical role in language acquisition and reading development. Here we employed electroencephalography (EEG) with frequency-tagging measures to track the temporal evolution of speech-structure learning in individuals with reading difficulties due to developmental dyslexia and in typical readers. We measured EEG while participants listened to (a) a structured stream of repeated tri-syllabic pseudowords, (b) a random stream of the same isochronous syllables, and (c) a series of tri-syllabic real Dutch words. Participants’ behavioral learning outcome (pseudoword recognition) was measured after training. We found that syllable-rate tracking was comparable between the two groups and stable across both the random and structured streams of syllables. More importantly, we observed a gradual emergence of the tracking of tri-syllabic pseudoword structures in both groups. Compared to the typical readers, however, in the dyslexic readers this implicit speech structure learning seemed to build up at a slower pace. A brain-behavioral correlation analysis showed that slower learners (i.e., participants who were slower in establishing the neural tracking of pseudowords) were less skilled in phonological awareness. Moreover, those who showed stronger neural tracking of real words tended to be less fluent in the visual-verbal conversion of linguistic symbols. Taken together, our study provides an online neurophysiological approach to track the progression of implicit learning processes and gives insights into the learning difficulties associated with dyslexia from a dynamic perspective.}
}

@book{Bonte2020, 
    place={Amsterdam, Amsterdam}, 
    title={Bestaat Dyslexie?: En is het een relevante vraag?}, 
    publisher={uitgeverij SWP}, 
    author={Bonte, Milene}, 
    year={2020}
} 

@article{Kleijnen2008,
  title={Dyslexie: Diagnose en behandeling van dyslexie},
  author={Kleijnen, R ea and Bosman, A and De Jong, P and Henneman, K and Pasman, J and Paternotte, A and Ruijssenaars, A and Struiksma, A and Van den Bos, KP and Van der Leij, A and others},
  year={2008},
  publisher={Bilthoven4eStichting Dyslexie Nederland (SDN)}
}

@article{VanVreckem2015,
  author       = {Van Vreckem, C. and Desoete, A.},
  issn         = {{1370-706X}},
  journal      = {{LOGOPEDIE}},
  language     = {{dut}},
  pages        = {{58--66}},
  title        = {{Het ene kind met dyslexie is het andere niet: implicaties uit begrijpend leesonderzoek en spellingonderzoek voor diagnostiek en therapie}},
  year         = {{2015}},
}

@book{Desoete2015, title={Dyscalculie}, publisher={Academia Press}, author={Desoete, A. and Vanderswalmen, R. and Bondt, A. De and Van, C. Vreckem and Vooren, V. Van and Beken, I. Vander and Dycke, S. Van and Baert, J.}, year={2015}} 

@article{Desoete2017,
author = {Desoete, Annemie},
year = {2017},
pages = {},
title = {Comorbiditeit bij leerstoornissen}
}

@article{Dirks2008,
author = {Dirks, Evelien and Spyer, Ginny and Van Lieshout, Ernest and de Sonneville, Leo},
year = {2008},
month = {09},
pages = {460-73},
title = {Prevalence of Combined Reading and Arithmetic Disabilities},
volume = {41},
journal = {Journal of learning disabilities},
doi = {10.1177/0022219408321128}
}

@misc{DeCraemer2018, title={Aan de slag met voorleessoftware op school. Een gids met 8 vragen en antwoorden.}, url={https://onderwijs.vlaanderen.be/nl/onderwijspersoneel/van-basis-tot-volwassenenonderwijs/lespraktijk/ict-in-de-klas/voorleessoftware-voor-leerlingen-met-leesbeperkingen/aan-de-slag-met-voorleessoftware-op-school}, journal={Aan de slag met voorleessoftware op school: Een gids met acht vragen en antwoorden.}, publisher={Onderwijs Vlaanderen}, author={De Craemer, Jan and Van Beeumen, Luc and Cooreman, Anny and Moonen, Ann and Rottier, Jan and Wagemakers, Inge and Mardulier, Theo}, year={2018}} 

@misc{OnderwijsVlaanderen2023, title={Voorleessoftware voor Leerlingen met Leesbeperkingen}, url={https://onderwijs.vlaanderen.be/voorleessoftware-voor-leerlingen-met-leesbeperkingen}, journal={Vlaams Ministerie van Onderwijs en Vorming}, publisher={Onderwijs Vlaanderen}, author={{Departement onderwijs en vorming}}, year={2023}} 

@article{Khurana2022,
author = {Khurana, Diksha and Koli, Aditya and Khatter, Kiran and Singh, Sukhdev},
year = {2022},
month = {07},
pages = {25-27},
publisher = {Springer Nature},
title = {Natural Language Processing: State of The Art, Current Trends and Challenges},
volume = {82},
journal = {Multimedia Tools and Applications}
}

@article{Goyal2022,
title={News Summarization and Evaluation in the Era of GPT-3},
author ={Tanya Goyal, Junyi Jessy Li, Greg Durrett},
year = {2022},
journal={arXiv preprint}
}

@inproceedings{Shardlow2013,
    title = "A Comparison of Techniques to Automatically Identify Complex Words.",
    author = "Shardlow, Matthew",
    booktitle = "51st Annual Meeting of the Association for Computational Linguistics Proceedings of the Student Research Workshop",
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P13-3015",
    pages = "103--109",
}

@inproceedings{Paetzold2016,
    title = "{S}em{E}val 2016 Task 11: Complex Word Identification",
    author = "Paetzold, Gustavo  and
      Specia, Lucia",
    booktitle = "Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)",
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S16-1085",
    doi = "10.18653/v1/S16-1085",
    pages = "560--569",
}

 @misc{Chauchan2018, title={Unsupervised text summarization using sentence embeddings}, url={https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1}, journal={Medium}, publisher={Medium}, author={Chauhan, Kushal}, year={2018}} 

@inproceedings{Gooding2019,
  title={Complex word identification as a sequence labelling task},
  author={Gooding, Sian and Kochmar, Ekaterina},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1148--1153},
  year={2019}
}

@book{Avontuur2015, place={Amsterdam, Amsterdam}, title={Dyslexie bij volwassenen: Impact op studie en Beroep}, publisher={Uitgeverij boom/nelissen}, author={Avontuur, Jos}, year={2015}} 

@misc{Lisowski2023, title={GPT-3 vs. CHATGPT. the key differences}, url={https://addepto.com/blog/gpt-3-vs-chat-gpt-the-key-differences/}, journal={Addepto}, publisher={Addepto}, author={Lisowski, Edwin}, year={2023}} 

@misc{Bosmans2022a, title={Woordgebruik - Synoniemen}, url={https://www.vlaanderen.be/taaladvies/taaladviezen/teksten-schrijven/formulering/woordgebruik-synoniemen}, journal={www.vlaanderen.be}, publisher={Vlaamse overheid}, author={Bosmans, An and Croon, Stefaan and Verreycken, Veronique}, year={2022}} 

@misc{Bosmans2022b, title={Woordgebruik - Moeilijke Woorden}, url={https://www.vlaanderen.be/taaladvies/taaladviezen/teksten-schrijven/formulering/woordgebruik-moeilijke-woorden}, journal={www.vlaanderen.be}, publisher={Vlaamse overheid}, author={Bosmans, An and Croon, Stefaan and Verreycken, Veronique}, year={2022}} 

@misc{Bosmans2022c, title={Woordgebruik - Moeilijke constructies}, url={https://www.vlaanderen.be/taaladvies/taaladviezen/teksten-schrijven/formulering/zinsbouw-moeilijke-constructies}, journal={www.vlaanderen.be}, publisher={Vlaamse overheid}, author={Bosmans, An and Croon, Stefaan and Verreycken, Veronique}, year={2022}}

@article{Binz2023,
	year = 2023,
	publisher = {Proceedings of the National Academy of Sciences},
	volume = {120},
	number = {6},
	author = {Marcel Binz and Eric Schulz},
    title = {Using cognitive psychology to understand GPT-3},
  	journal = {Proceedings of the National Academy of Sciences}
}

@misc{Mottesi2023, title={GPT-3 vs. Bert: Comparing the two most popular language models}, 
    url={https://blog.invgate.com/gpt-3-vs-bert}, 
    journal={IT Management Software}, 
    publisher={InvGate Inc.}, 
    author={Mottesi, Celeste}, 
    year={2023}
} 

@misc{Rijkhoff2022, title={Tekst Inkorten?: 9 tips om Je Teksten korter Te Maken}, url={https://dialoogtrainers.nl/tekst-inkorten-tips/}, journal={Dialoogtrainers}, publisher={Dialoogtrainers}, author={Rijkhoff, Jeffrey}, year={2022}} 

@article{RiveroContreras2021,
  title={An experimental eye-tracking study of text adaptation for readers with dyslexia: effects of visual support and word frequency},
  author={Miriam Rivero-Contreras and Paul E. Engelhardt and David Salda{\~n}a},
  journal={Annals of Dyslexia},
  year={2021},
  volume={71},
  pages={170-187}
}

@misc{Stiennon2020,
  author = {Stiennon, Nisan and Ouyang, Long and Wu, Jeff and Ziegler, Daniel M. and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Learning to summarize from human feedback},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Rello2013a,
    author = {Rello, Luz and Baeza-Yates, Ricardo and Dempere-Marco, Laura and Saggion, Horacio},
    year = {2013},
    month = {09},
    pages = {},
    title = {Frequent Words Improve Readability and Short Words Improve Understandability for People with Dyslexia},
    isbn = {978-3-642-40497-9},
}

@inproceedings{Nenkova2004,
    title = "Evaluating Content Selection in Summarization: The Pyramid Method",
    author = "Nenkova, Ani  and Passonneau, Rebecca",
    booktitle = "Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004",
    year = "2004",
    address = "Boston, Massachusetts, USA",
    publisher = "Association for Computational Linguistics",
    pages = "145--152",
}

@inproceedings{Lin2004,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@article{Ganesan2018,
    author = {Ganesan, Kavita},
    year = {2018},
    month = {03},
    pages = {},
    title = {ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks}
}

@inproceedings{ShafieiBavani2018,
    author = {ShafieiBavani, Elaheh and Ebrahimi, Mohammad and Wong, Raymond and Chen, Fang},
    year = {2018},
    month = {01},
    pages = {762-767},
    title = {A Graph-theoretic Summary Evaluation for ROUGE},
    doi = {10.18653/v1/D18-1085}
}

@misc{Hsu2018,
  author = {Hsu, Wan-Ting and Lin, Chieh-Kai and Lee, Ming-Ying and Min, Kerui and Tang, Jing and Sun, Min},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{Huang2019,
  author={Huang, Si and Wang, Rui and Xie, Qing and Li, Lin and Liu, Yongjian},
  booktitle={2019 6th International Conference on Behavioral, Economic and Socio-Cultural Computing (BESC)}, 
  title={An Extraction-Abstraction Hybrid Approach for Long Document Summarization}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
}

@misc{Daoud2023, title={Vandaag Internationale Dag van de Moedertaal: Pleidooi voor Het Nederlands}, url={https://doorbraak.be/vandaag-internationale-dag-van-de-moedertaal-pleidooi-voor-het-nederlands/}, journal={Doorbraak.be}, publisher={Doorbraak}, author={Daoud, Nabilla Ait}, year={2023}} 

@Online{Diels2022, title={Over dyslexie, vooroordelen en vriendschap}, url={https://www.maastrichtuniversity.nl/nl/nieuws/over-dyslexie-vooroordelen-en-vriendschap}, journal={Universiteit Maastricht }, publisher={Universiteit Maastricht}, author={Diels, Ludo}, year={2022}} 

@misc{VanDerMeer2022, title={Dyslexie hebben is Niet Zo Raar: Lezen is iets heel onnatuurlijks}, url={https://www.demorgen.be/beter-leven/dyslexie-hebben-is-niet-zo-raar-lezen-is-iets-heel-onnatuurlijks~bc608101/}, journal={De Morgen}, publisher={De Morgen}, author={van der Meer, Claire}, year={2022}} 

@article{Romanovska2021,
    author = {Romanovska, Linda and Bonte, Milene},
    year = {2021},
    month = {12},
    title = {How Learning to Read Changes the Listening Brain},
    volume = {12},
    journal = {Frontiers in Psychology}
}

@article{Vellutino2004,
    author = {Vellutino, Frank and Fletcher, Jack and Snowling, Margaret and Scanlon, Donna},
    year = {2004},
    month = {02},
    pages = {2-40},
    title = {Specific reading disability (dyslexia): What have we learned in the past four decades?},
    volume = {45},
    journal = {Journal of child psychology and psychiatry, and allied disciplines}
}

@incollection{Hickok2016,
    title = {Chapter 63 - Acquired Dyslexia},   
    editor = {Hickok, Gregory and Small, Steven L.},
    booktitle = {Neurobiology of Language},
    publisher = {Academic Press},
    address = {San Diego},
    pages = {791-803},
    year = {2016},
    isbn = {978-0-12-407794-2},
    author = {H. Branch Coslett and Peter Turkeltaub},
    keywords = {dyslexia, reading, reading disorders},
    abstract = {Disorders of reading are frequently encountered in patients with acquired cerebral lesions. Although these disorders were first investigated in the 19th century, investigations in the past few decades have greatly improved our understanding of the dyslexias. In this chapter, we start with a discussion of the “peripheral” dyslexias that are attributable to disorders of the processing of words as a visual stimulus. We then turn to a discussion of the “central” dyslexias, including deep, surface, and phonological dyslexia that are typically associated with impairments in basic language faculties such as semantics and phonology. Mechanistic accounts of the dyslexias, including well-described computational accounts of the central dyslexias, are discussed. Finally, we briefly describe the reading tasks that serve to differentiate the different reading disorders.}
}

@book{Uhry2008, 
    place={Austin, TX, Texas}, 
    title={Dyslexia: Theory and practice of instruction}, 
    publisher={Pro-ed}, 
    author={Uhry, Joanna Kellog and Clark, Diana Brewster}, 
    year={2008}
} 

@inproceedings{Rello2017,
    author = {Rello, Luz and Bigham, Jeffrey},
    year = {2017},
    month = {10},
    pages = {72-80},
    title = {Good Background Colors for Readers: A Study of People with and without Dyslexia}
}

@misc{Leopold2015,
    author = {Leopold, A},
    title = {todo},
    year = {2015}
}

@misc{Ribas2023, title={Building the new bing}, url={https://www.linkedin.com/pulse/building-new-bing-jordi-ribas/}, journal={LinkedIn}, publisher={Microsoft}, author={Ribas, Jordi}, year={2023}} 

@misc{Hale2022, title={Bullet points: What, why, and how to use then}, url={https://www.contentandcommas.com/bullet-points/}, journal={Content and Commas}, author={Hale, Alexis}, year={2022}} 

@article{JavoureyDrevet2022, title={Simplification of literary and scientific texts to improve reading fluency and comprehension in beginning readers of French}, volume={43}, DOI={10.1017/S014271642100062X}, number={2}, journal={Applied Psycholinguistics}, publisher={Cambridge University Press}, author={Javourey-Drevet, Ludivine and Dufau, Stéphane and François, Thomas and Gala, Núria and Ginestié, Jacques and Ziegler, Johannes C.}, year={2022}, pages={485–512}}

@inproceedings{Aroyehun2018,
    title = "Complex Word Identification: Convolutional Neural Network vs. Feature Engineering",
    author = "Aroyehun, Segun Taofeek  and
      Angel, Jason  and
      P{\'e}rez Alvarez, Daniel Alejandro  and
      Gelbukh, Alexander",
    booktitle = "Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications",
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pages = "322--327",
    abstract = "We describe the systems of NLP-CIC team that participated in the Complex Word Identification (CWI) 2018 shared task. The shared task aimed to benchmark approaches for identifying complex words in English and other languages from the perspective of non-native speakers. Our goal is to compare two approaches: feature engineering and a deep neural network. Both approaches achieved comparable performance on the English test set. We demonstrated the flexibility of the deep-learning approach by using the same deep neural network setup in the Spanish track. Our systems achieved competitive results: all our systems were within 0.01 of the system with the best macro-F1 score on the test sets except on Wikipedia test set, on which our best system is 0.04 below the best macro-F1 score.",
}

@article{Althunayyan2021,
    author = {Althunayyan, Suha and Azmi, Aqil},
    year = {2021},
    month = {03},
    pages = {Article no. 43},
    title = {Automated Text Simplification: A Survey},
    volume = {54},
    journal = {ACM Computing Surveys},
    doi = {10.1145/3442695}
}

@misc{Rijnvis2020, 
    title={Tangconstructies - 5 tips om ze Te Vermijden}, 
    url={https://www.schrijfvis.nl/tangconstructies/}, 
    journal={Schrijfvis}, 
    publisher={Schrijfvis}, 
    author={Rijnvis, Dennis}, 
    year={2020}
} 

@misc{Ribeiro2018,
    author = {Ribeiro, Eugénio and Ribeiro, Ricardo and de Matos, David Martins},
    keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences, H.1.2; H.3.1; I.2.7},
    title = {A Study on Dialog Act Recognition using Character-Level Tokenization},
    publisher = {arXiv},
    year = {2018}
}

@misc{Iredale2022, title={An overview of tokenization algorithms in NLP}, url={https://101blockchains.com/tokenization-nlp/}, journal={101 Blockchains}, publisher={101 Blockchains}, author={Iredale, Gwyneth}, year={2022}, month={Aug}} 

@misc{Fardeen2021, title={Complete Guide to Spacy Tokenizer with examples}, url={https://machinelearningknowledge.ai/complete-guide-to-spacy-tokenizer-with-examples/}, journal={Machine Learning Knowledge}, author={Fardeen-, ByAfham}, year={2021}, month={Jul}} 

@misc{Garg2022, 
    title={Using GPT-3 for education: Use cases}, 
    url={https://indiaai.gov.in/article/using-gpt-3-for-education-use-cases}, 
    journal={AI Portal of India}, 
    publisher={AI Portal of India}, 
    author={Garg, Harish}, 
    year={2022}, 
    month={Sep}
} 

@misc{Hern2023, 
    title={TechScape: Will meta's massive leak democratise AI – and at what cost?}, 
    url={https://www.theguardian.com/technology/2023/mar/07/techscape-meta-leak-llama-chatgpt-ai-crossroads},   
    journal={The Guardian}, 
    publisher={Guardian News and Media}, 
    author={Hern, Alex}, 
    year={2023}, 
    month={Mar}
} 

@misc{Touvron2023,
    author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
    keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {LLaMA: Open and Efficient Foundation Language Models},
    publisher = {arXiv},
    year = {2023},
    copyright = {Creative Commons Attribution 4.0 International}
}

@misc{Roose2023, 
    title={Don't ban chatgpt in schools. teach with it.}, 
    url={https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html}, 
    journal={The New York Times}, 
    publisher={The New York Times}, 
    author={Roose, Kevin}, 
    year={2023}, 
    month={Jan}
}


@misc{Brown2020,
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Language Models are Few-Shot Learners},
  publisher = {arXiv},
  year = {2020}
}

@misc{Simon2021, 
    title={Large language models: A new moore's law?}, 
    url={https://huggingface.co/blog/large-language-models}, 
    journal={Hugging Face}, 
    publisher={Hugging Face}, 
    author={Simon, Julien}, 
    year={2021}, 
    month={Oct}
} 

@misc{Li2022, 
    title={OpenAI's GPT-3 language model: A technical overview}, 
    url={https://lambdalabs.com/blog/demystifying-gpt-3}, 
    journal={GPU Cloud, Workstations, Servers, Laptops for Deep Learning}, 
    publisher={Lambda, Inc.}, 
    author={Li, Chuan}, 
    year={2022}, 
    month={Aug}
} 

@misc{Strubell2019,
  author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Energy and Policy Considerations for Deep Learning in NLP},
  publisher = {arXiv},
  year = {2019},
}

@misc{Hollenkamp2020, 
    title={Summary and analysis of Scientific Research Articles - San Jose State ...}, 
    url={https://www.sjsu.edu/writingcenter/docs/handouts/Summary%20and%20Analysis%20of%20Scientific%20Research%20Articles.pdf}, 
    journal={San José State University Writing Center}, 
    publisher={San José State University Writing Center}, 
    author={Hollenkamp, Joseph}, year={2020}} 

@misc{Case2008, 
    title={More ways of simplifying your classroom language}, 
    url={https://www.tefl.net/elt/articles/teacher/how-to-simplify-your-classroom-language/}, 
    journal={Tefl.NET}, 
    publisher={Tefl.NET}, 
    author={Case, Alex},  
    year={2008}, 
    month={Sep}
} 

 @misc{Menzli2023, 
    title={Tokenization in NLP: Types, challenges, examples, tools}, 
    url={https://neptune.ai/blog/tokenization-in-nlp}, 
    journal={neptune.ai}, 
    publisher={neptune.ai}, 
    author={Menzli, Amal}, 
    year={2023}, 
    month={Jan}
} 

@article{Suleiman2020,
    author = {Suleiman, Dima and Awajan, Arafat},
    year = {2020},
    month = {08},
    title = {Deep Learning Based Abstractive Text Summarization: Approaches, Datasets, Evaluation Measures, and     Challenges},
    volume = {2020},
    journal = {Mathematical Problems in Engineering}
}

@article{Louwerse2007,
    author = {Louwerse, Max and Mccarthy, Philip and McNamara, Danielle},
    year = {2007},
    month = {03},
    pages = {15 - 30},
    title = {A Linguistic Analysis of Simplified and Authentic Texts},
    volume = {91},
    journal = {The Modern Language Journal}
}


@article{Crossley2012,
    author = {Scott A. Crossley and David Allen and Danielle S. McNamara},
    title ={Text simplification and comprehensible input: A case for an intuitive approach},
    journal = {Language Teaching Research},
    volume = {16},
    number = {1},
    pages = {89-108},
    year = {2012},
    abstract = { Texts are routinely simplified to make them more comprehensible for second language learners. However, the effects of simplification upon the linguistic features of texts remain largely unexplored. Here we examine the effects of one type of text simplification: intuitive text simplification. We use the computational tool, Coh-Metrix, to examine linguistic differences between proficiency levels of a corpus of 300 news texts that had been simplified to three levels of simplification (beginner, intermediate, advanced). The main analysis reveals significant differences between levels for a wide range of linguistic features, particularly between beginner and advanced levels. The results show that lower level texts are generally less lexically and syntactically sophisticated than higher-level texts. The analysis also reveals that lower level texts contain more cohesive features than higher-level texts. The analysis also provides strong evidence that these linguistic features can be used to classify levels of simplified reading texts. Overall, the findings support the notion that intuitively simplified texts at the beginning level contain more linguistic features related to comprehensible input than intuitively simplified texts at the advanced level. }
}

@misc{Liu2021,
  author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},  
  title = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},  
  publisher = {arXiv},  
  year = {2021},  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@misc{IBM2022, 
    title={IBM Global  AI Adoption  Index 2022}, 
    url={https://www.ibm.com/downloads/cas/GVAGA3JP}, 
    journal={Report Global AI Adoption}, 
    publisher={IBM}, 
    author={IBM}, 
    year={2022}, 
    month={May}
} 

@misc{Chiusano2022, 
    title={Two minutes NLP - learn the Rouge metric by examples}, 
    url={https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499},  
    journal={Medium}, 
    publisher={NLPlanet},  
    author={Chiusano, Fabio}, 
    year={2022}, 
    month={Apr}
} 

@misc{McCombes2022, 
    title={How to write A summary: Guide &amp; examples}, 
    url={https://www.scribbr.com/working-with-sources/how-to-summarize/}, 
    journal={Scribbr}, 
    author={McCombes, Shona}, 
    year={2022}, 
    month={Nov}
} 

@article{Steinberger2009,
    author = {Steinberger, Josef and Jezek, Karel},
    year = {2009},
    month = {01},
    pages = {251-275},
    title = {Evaluation Measures for Text Summarization.},
    volume = {28},
    journal = {Computing and Informatics}
}

@misc{Weinberg2023, 
    title={Duckduckgo launches DuckAssist}, 
    url={https://spreadprivacy.com/duckassist-launch/}, 
    journal={Spread Privacy}, 
    publisher={Spread Privacy}, 
    author={Weinberg, Gabriel}, 
    year={2023}, 
    month={Mar}
} 

@misc{Mcauliffe2023, 
    title={DuckDuckGo introduces new AI feature: DuckAssist}, 
    url={https://www.cnet.com/tech/services-and-software/meet-duckassist-duckduckgos-new-ai-feature/}, 
    journal={CNET}, 
    publisher={CNET}, 
    author={McAuliffe, Zachary}, 
    year={2023}, 
    month={Mar}
}

@misc{Brockman2023, 
    title={Introducing chatgpt and Whisper Apis}, url={https://openai.com/blog/introducing-chatgpt-and-whisper-apis}, 
    journal={Introducing ChatGPT and Whisper APIs}, 
    publisher={OpenAI}, 
    author={Greg, Brockman and Atty, Eleti and Elie, Georges and Joane, Jang and Logan, Kilpatrick and Lim, Rachel and Luke, Miller and Michelle, Pokrass}, 
    year={2023}, 
    month={Mar}
} 

@article{Radford2019,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{Liu2020,
  author = {Liu, Qi and Kusner, Matt J. and Blunsom, Phil},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey on Contextual Embeddings},
  publisher = {arXiv},
  year = {2020}
}

@misc{Anthony2020, 
    title={Website design trends for dyslexia and ADHD}, 
    url={https://www.verndale.com/insights/accessibility/website-design-trends-for-dyslexia-and-adhd}, 
    journal={Verndale}, 
    publisher={Verndale}, 
    author={Anthony, Chris}, 
    year={2020}, 
    month={Oct}
} 

@inproceedings{Rello2013b,
    author = {Rello, Luz and Baeza-Yates, Ricardo},
    year = {2013},
    month = {10},
    pages = {},
    title = {Good fonts for dyslexia},
    journal = {Proceedings of the 15th International ACM SIGACCESS Conference on Computers and Accessibility, ASSETS 2013}
}

@article{Rello2015,
  title={How to present more readable text for people with dyslexia},
  author={Rello, Luz and A. Baeza-Yates, Ricardo},
  journal={Universal Access in the Information Society},
  year={2015},
  volume={16},
  pages={29-49}
}

@inproceedings{Rello2013c,
    author = {Rello, Luz and Baeza-Yates, Ricardo and Saggion, Horacio},
    year = {2013},
    month = {03},
    pages = {501-512},
    title = {The Impact of Lexical Simplification by Verbal Paraphrases for People with and without Dyslexia},
    volume = {7817},
    isbn = {978-3-642-37255-1}
}


@inproceedings{Rello2012b,
    author = {Rello, Luz and Saggion, Horacio and Baeza-Yates, Ricardo and Graells, Eduardo},
    year = {2012},
    month = {06},
    pages = {25-32},
    title = {Graphical schemes may improve readability but not understandability for people with dyslexia}
}

@article{Nandhini2013,
    title = {Improving readability through extractive summarization for learners with reading difficulties},
    journal = {Egyptian Informatics Journal},
    volume = {14},
    number = {3},
    pages = {195-204},
    year = {2013},
    issn = {1110-8665},
    author = {K. Nandhini and S.R. Balasundaram},
    keywords = {Text summarization, Extractive summarization, Machine learning, Naive Bayes classifier, Assistive reading},

    abstract = {In this paper, we describe the design and evaluation of extractive summarization approach to assist the learners with reading difficulties. As existing summarization approaches inherently assign more weights to the important sentences, our approach predicts the summary sentences that are important as well as readable to the target audience with good accuracy. We used supervised machine learning technique for summary extraction of science and social subjects in the educational text. Various independent features from the existing literature for predicting important sentences and proposed learner dependent features for predicting readable sentences are extracted from texts and are used for automatic classification. We performed both extrinsic and intrinsic evaluation on this approach and the intrinsic evaluation is carried out using F-measure and readability analysis. The extrinsic evaluation comprises of learner feedback using likert scale and the effect of assistive summary on improving readability for learners’ with reading difficulty using ANOVA. The results show significant improvement in readability for the target audience using assistive summary.}
}

@article{Linderholm2000,
author = { Tracy   Linderholm  and  Michelle Gaddy   Everson  and  Paul   van den Broek  and  Maureen   Mischinski  and  Alex   Crittenden  and  Jay   Samuels },
title = {Effects of Causal Text Revisions on More- and Less-Skilled Readers' Comprehension of Easy and Difficult Texts},
journal = {Cognition and Instruction},
volume = {18},
number = {4},
pages = {525-556},
year  = {2000},
publisher = {Routledge}
}

@book{Tops2018, 
    place={Gent, België}, 
    title={Slagen met Dyslexie in Het Hoger Onderwijs}, 
    publisher={Owl Press}, 
    author={Tops, Wim and Callens, Maaike and Brysbaert, Marc and Schouten, Emma Laura}, 
    year={2018}
} 

@misc{Murdos2014, 
    title={Examining the readability of research abstracts to Determine Whether  the General Public Can Understand Key Findings in Science}, 
    url={https://ctsi.ucla.edu/education/files/view/docs/06_08_2016_PALM_Communication_of_Science_Poster.pdf}, 
    journal={UCLA Clinical and Translational Science Institute}, 
    publisher={UCLA Clinical and Translational Science Institute}, 
    author={Murdos, Amjad and Hodges, Meghan and Rubio, Diego and Adams, John S.}, 
    year={2014}
} 

@misc{McFarland2023, title={What is prompt engineering in AI &amp; Why It Matters}, url={https://www.unite.ai/what-is-prompt-engineering-in-ai-why-it-matters/}, journal={Unite.AI}, publisher={Unite.AI}, author={McFarland, Alex}, year={2023}, month={Feb}}

@misc{Jiang2023, title={Prompt engineering : Deconstructing and managing intention}, url={https://www.linkedin.com/pulse/prompt-engineering-deconstructing-managing-intention-jiang/}, journal={LinkedIn}, publisher={Creative Ecologist Take}, author={Jiang, Ryan K.L.}, year={2023}, month={Mar}
}

@misc{White2023,
  author = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C.},  
  keywords = {Software Engineering (cs.SE), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},  
  title = {A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT},  
  publisher = {arXiv},  
  year = {2023},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}  

@misc{Harwell2023, 
    title={Tech's hottest new job: Ai whisperer. no coding required.}, 
    url={https://www.washingtonpost.com/technology/2023/02/25/prompt-engineers-techs-next-big-job/}, 
    journal={The Washington Post}, 
    publisher={WP Company}, 
    author={Harwell, Drew}, 
    year={2023}, 
    month={Feb}
} 


@misc{Miszczak2023, title={Prompt engineering: The ultimate guide 2023 [GPT-3 &amp; chatgpt]}, url={https://businessolution.org/prompt-engineering/}, journal={businessolution.org}, author={Miszczak, Patryk}, year={2023}, month={Feb}} 

@misc{Dandekar2016, title={How to use machine learning to find synonyms}, url={https://medium.com/@nikhilbd/how-to-use-machine-learning-to-find-synonyms-6380c0c6106b}, journal={Medium}, publisher={Medium}, author={Dandekar, Nikhil}, year={2016}, month={May}} 

@misc{Fabbri2020,
  author = {Fabbri, Alexander R. and Kryściński, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard and Radev, Dragomir},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {SummEval: Re-evaluating Summarization Evaluation},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Iskender2021,
    title = "Reliability of Human Evaluation for Text Summarization: Lessons Learned and Challenges Ahead",
    author = {Iskender, Neslihan  and
      Polzehl, Tim  and
      M{\"o}ller, Sebastian},
    booktitle = "Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)",
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.humeval-1.10",
    pages = "86--96",
    abstract = "Only a small portion of research papers with human evaluation for text summarization provide information about the participant demographics, task design, and experiment protocol. Additionally, many researchers use human evaluation as gold standard without questioning the reliability or investigating the factors that might affect the reliability of the human evaluation. As a result, there is a lack of best practices for reliable human summarization evaluation grounded by empirical evidence. To investigate human evaluation reliability, we conduct a series of human evaluation experiments, provide an overview of participant demographics, task design, experimental set-up and compare the results from different experiments. Based on our empirical analysis, we provide guidelines to ensure the reliability of expert and non-expert evaluations, and we determine the factors that might affect the reliability of the human evaluation.",
}

@misc{Raj2017, 
    title={Metrics for NLG evaluation}, 
    url={https://medium.com/explorations-in-language-and-learning/metrics-for-nlg-evaluation-c89b6a781054}, 
    journal={Medium}, 
    publisher={Explorations in Language and Learning}, 
    author={Raj, Desh}, 
    year={2017}, 
    month={Sep}
} 

@misc{Vlaanderen2020, 
author={{Onderwijsinspectie Overheid Vlaanderen}},
url={https://www.vlaanderen.be/publicaties/begrijpend-leesonderwijs-in-de-basisscholen-kwaliteitsvol-sterke-en-zwakke-punten-van-de-huidige-praktijk}, journal={www.vlaanderen.be}, publisher={Vlaamse overheid}, year={2020}, month={Mar}} 

@misc{Tatman2019, title={Evaluating text output in NLP: Bleu at your own risk}, url={https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213}, journal={Medium}, publisher={Towards Data Science}, author={Tatman, Rachael}, year={2019}, month={Jul}} 

@article{Kraft2020,
author = {Matthew A. Kraft},
title ={Interpreting Effect Sizes of Education Interventions},
journal = {Educational Researcher},
volume = {49},
number = {4},
pages = {241-253},
year = {2020},
doi = {10.3102/0013189X20912798},
URL = {https://doi.org/10.3102/0013189X20912798},
abstract = { Researchers commonly interpret effect sizes by applying benchmarks proposed by Jacob Cohen over a half century ago. However, effects that are small by Cohen’s standards are large relative to the impacts of most field-based interventions. These benchmarks also fail to consider important differences in study features, program costs, and scalability. In this article, I present five broad guidelines for interpreting effect sizes that are applicable across the social sciences. I then propose a more structured schema with new empirical benchmarks for interpreting a specific class of studies: causal research on education interventions with standardized achievement outcomes. Together, these tools provide a practical approach for incorporating study features, costs, and scalability into the process of interpreting the policy importance of effect sizes. }
}

@article{Belpaeme2018,
  title={Social robots for education: A review},
  author={Belpaeme, Tony and Kennedy, James and Ramachandran, Aditi and Scassellati, Brian and Tanaka, Fumihide},
  journal={Science robotics},
  volume={3},
  number={21},
  pages={eaat5954},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@misc{CAS2021, 
author={{Charlesworth Author Services}},
url={https://www.cwauthors.com/article/How-to-write-about-complex-scientific-concepts-in-simple-accessible-language}, journal={How to make complex scientific concepts more accessible - Charlesworth Author Services}, publisher={Charlesworth Author Services}, year={2021}, month={Sep}} 

@inproceedings{Santana2012,
author = {Santana, Vagner and Oliveira, Rosimeire and Almeida, Leonelo and Baranauskas, M. Cecilia},
year = {2012},
month = {04},
pages = {},
title = {Web accessibility and people with dyslexia: A survey on techniques and guidelines},
journal = {W4A 2012 - International Cross-Disciplinary Conference on Web Accessibility},
doi = {10.1145/2207016.2207047}
}

@inproceedings{Zhou2019,
    title = "{BERT}-based Lexical Substitution",
    author = "Zhou, Wangchunshu  and
      Ge, Tao  and
      Xu, Ke  and
      Wei, Furu  and
      Zhou, Ming",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1328",
    doi = "10.18653/v1/P19-1328",
    pages = "3368--3373",
    abstract = "Previous studies on lexical substitution tend to obtain substitute candidates by finding the target word{'}s synonyms from lexical resources (e.g., WordNet) and then rank the candidates based on its contexts. These approaches have two limitations: (1) They are likely to overlook good substitute candidates that are not the synonyms of the target words in the lexical resources; (2) They fail to take into account the substitution{'}s influence on the global context of the sentence. To address these issues, we propose an end-to-end BERT-based lexical substitution approach which can propose and validate substitute candidates without using any annotated data or manually curated resources. Our approach first applies dropout to the target word{'}s embedding for partially masking the word, allowing BERT to take balanced consideration of the target word{'}s semantics and contexts for proposing substitute candidates, and then validates the candidates based on their substitution{'}s influence on the global contextualized representation of the sentence. Experiments show our approach performs well in both proposing and ranking substitute candidates, achieving the state-of-the-art results in both LS07 and LS14 benchmarks.",
}

@article{Zorzi2012,
  title={Extra-large letter spacing improves reading in dyslexia},
  author={Zorzi, Marco and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={109},
  number={28},
  pages={11455--11459},
  year={2012},
  publisher={National Acad Sciences}
}

@article{Galliussi2020,
  title={Inter-letter spacing, inter-word spacing, and font with dyslexia-friendly features: testing text readability in people with and without dyslexia},
  author={Galliussi, Jessica and others},
  journal={Annals of Dyslexia},
  volume={70},
  pages={141--152},
  year={2020},
  publisher={Springer}
}

@inproceedings{Sanja2021,
author = {Stajner, Sanja},
year = {2021},
month = {01},
pages = {2637-2652},
title = {Automatic Text Simplification for Social Good: Progress and Challenges},
doi = {10.18653/v1/2021.findings-acl.233}
}

@inproceedings{Rello2013d,
author = {Rello, Luz and Baeza-Yates, Ricardo and Bott, Stefan and Saggion, Horacio},
title = {Simplify or Help? Text Simplification Strategies for People with Dyslexia},
year = {2013},
isbn = {9781450318440},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2461121.2461126},
doi = {10.1145/2461121.2461126},
abstract = {We present a user study for two different automatic strategies that simplify text content for people with dyslexia. The strategies considered are the standard one (replacing a complex word with the most simpler synonym) and a new one that presents several synonyms for a complex word if the user requests them. We compare texts transformed by both strategies with the original text and to a gold standard manually built. The study was undertook by 96 participants, 47 with dyslexia plus a control group of 49 people without dyslexia. To show device independence, for the new strategy we used three different reading devices. Overall, participants with dyslexia found texts presented with the new strategy significantly more readable and comprehensible. To the best of our knowledge, this is the largest user study of its kind.},
booktitle = {Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility},
articleno = {15},
numpages = {10},
keywords = {smartphone, tablet, laptop, readability, understandability, text simplification, dyslexia, eye-tracking},
location = {Rio de Janeiro, Brazil},
series = {W4A '13}
}

@article{VanBrakel2022,
title = "De controle op het gebruik van algoritmische surveillance- onder druk? Een exploratie door de lens van de relationele ethiek",
author = "{Van Brakel}, {Rosamunde Elise}",
year = "2022",
language = "Dutch",
volume = "2022",
pages = "23--28",
journal = "Tijdschrift voor Mensenrechten",
issn = "1379-0250",
number = "1",
}

@article{Ruelas2020,
author = {Ruelas Inzunza, Ernesto},
year = {2020},
month = {11},
pages = {563-565},
title = {Reconsidering the Use of the Passive Voice in Scientific Writing},
volume = {82},
journal = {The American Biology Teacher},
doi = {10.1525/abt.2020.82.8.563}
}

@misc{Sleuwaegen2022, title={Nederland versus België:&nbsp; verschillen in economische&nbsp; dynamiek en beleid}, url={https://feb.kuleuven.be/research/les/pdf/LES%202022%20-%20197.pdf}, journal={KU Leuven}, publisher={KU Leuven - Faculteit Economie en Bedrijfswetenschappen}, author={Sleuwaegen, Leo}, year={2022}, month={Nov}} 

@article{Fernando2021,
author = {Fernando H. F. Botelho},
title = {Accessibility to digital technology: Virtual barriers, real opportunities},
journal = {Assistive Technology},
volume = {33},
number = {sup1},
pages = {27-34},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/10400435.2021.1945705},
    note ={PMID: 34951832},
URL = {https://doi.org/10.1080/10400435.2021.1945705},
}

@article{Cantos2019,
author = {Cantos, Pascual and Almela, Ángela},
year = {2019},
month = {05},
pages = {31-52},
title = {Readability indices for the assessment of textbooks: a feasibility study in the context of EFL},
journal = {Vigo International Journal of Applied Linguistics},
doi = {10.35869/vial.v0i16.92}
}

@incollection{Matarese2013,
title = {5 - Using strategic, critical reading of research papers to teach scientific writing: the reading–research–writing continuum},
editor = {Valerie Matarese},
booktitle = {Supporting Research Writing},
publisher = {Chandos Publishing},
pages = {73-89},
year = {2013},
series = {Chandos Information Professional Series},
isbn = {978-1-84334-666-1},
doi = {https://doi.org/10.1016/B978-1-84334-666-1.50005-9},
url = {https://www.sciencedirect.com/science/article/pii/B9781843346661500059},
author = {Valerie Matarese},
keywords = {browsing, second-language reading, literature-based learning, peer discussion, small-group learning},
abstract = {Abstract:
Scientific literacy is a fundamental attribute that supports researchers in both research and research writing. This chapter describes the rationale and design of a course that uses strategic, critical reading to teach research writing to doctoral candidates. The course, ‘Effective Biomedical Reading and Writing’, was designed by an authors’ editor with scientific qualifications. In the course, students are guided through the independent writing of a research paper using their own data, according to a scheme in which a paper is built up around the results. Through reading and critical discussion of published papers representing a range of qualities and topics, students develop a framework of knowledge that helps them assess the effectiveness of their own writing. They are supported throughout the course, in reading and writing, by the instructor’s knowledge of the research topics and methodologies. Subject specialists who work as language professionals and who acquire language teaching skills are uniquely positioned to develop courses for doctoral students in their own fields.}
}

@article{Crossley2019,
author = {Crossley, Scott A. and Skalicky, Stephen and Dascalu, Mihai},
title = {Moving beyond classic readability formulas: new methods and new models},
journal = {Journal of Research in Reading},
volume = {42},
number = {3-4},
pages = {541-561},
keywords = {readability, natural language processing, crowdsourcing, text comprehension, text reading speed},
doi = {https://doi.org/10.1111/1467-9817.12283},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9817.12283},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9817.12283},
abstract = {Background Advances in natural language processing (NLP) and computational linguistics have facilitated major improvements on traditional readability formulas that aim at predicting the overall difficulty of a text. Recent studies have identified several types of linguistic features that are theoretically motivated and predictive of human judgments of text readability, which outperform predictions made by traditional readability formulas, such as Flesch–Kincaid. The purpose of this study is to develop new readability models using advanced NLP tools to measure both text comprehension and reading speed. Methods This study used crowdsourcing techniques to collect human judgments of text comprehension and reading speed across a diverse variety of topic domains (science, technology and history). Linguistic features taken from state-of-the-art NLP tools were used to develop models explaining human judgments of text comprehension and reading speed. The accuracy of these models was then compared with classic readability formulas. Results The results indicated that models employing linguistic features more theoretically related to text comprehension and reading speed outperform classic readability models. Conclusions This study developed new readability formulas based on advanced NLP tools for both text comprehension and reading speed. These formulas, based on linguistic features that better represent theoretical and behavioural accounts of the reading process, significantly outperformed classic readability formulas.},
year = {2019}
}

@article{Leroy2013,
title = {A user-study measuring the effects of lexical simplification and coherence enhancement on perceived and actual text difficulty},
journal = {International Journal of Medical Informatics},
volume = {82},
number = {8},
pages = {717-730},
year = {2013},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2013.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1386505613000592},
author = {Gondy Leroy and David Kauchak and Obay Mouradi},
keywords = {Comprehension, Readability, Health literacy, Consumer health information, Patient education, Information systems, Medical informatics computing},
abstract = {Purpose
Low patient health literacy has been associated with cost increases in medicine because it contributes to inadequate care. Providing explanatory text is a convenient approach to distribute medical information and increase health literacy. Unfortunately, writing text that is easily understood is challenging. This work tests two text features for their impact on understanding: lexical simplification and coherence enhancement.
Methods
A user study was conducted to test the features’ effect on perceived and actual text difficulty. Individual sentences were used to test perceived difficulty. Using a 5-point Likert scale, participants compared eight pairs of original and simplified sentences. Abstracts were used to test actual difficulty. For each abstract, four versions were created: original, lexically simplified, coherence enhanced, and lexically simplified and coherence enhanced. Using a mixed design, one group of participants worked with the original and lexically simplified documents (no coherence enhancement) while a second group worked with the coherence enhanced versions. Actual difficulty was measured using a Cloze measure and multiple-choice questions.
Results
Using Amazon's Mechanical Turk, 200 people participated of which 187 qualified based on our data qualification tests. A paired-samples t-test for the sentence ratings showed a significant reduction in difficulty after lexical simplification (p<.001). Results for actual difficulty are based on the abstracts and associated tasks. A two-way ANOVA for the Cloze test showed no effect of coherence enhancement but a main effect for lexical simplification, with the simplification leading to worse scores (p=.004). A follow-up ANOVA showed this effect exists only for function words when coherence was not enhanced (p=.008). In contrast, a two-way ANOVA for answering multiple-choice questions showed a significant beneficial effect of coherence enhancement (p=.003) but no effect of lexical simplification.
Conclusions
Lexical simplification reduced the perceived difficulty of texts. Coherence enhancement reduced the actual difficulty of text when measured using multiple-choice questions. However, the Cloze measure results showed that lexical simplification can negatively impact the flow of the text.}
}

@misc{Lee2021, title={Extract text from unsearchable pdfs for data analysis using Python}, url={https://medium.com/social-impact-analytics/extract-text-from-unsearchable-pdfs-for-data-analysis-using-python-a6a2ca0866dd}, journal={Medium}, publisher={Social Impact Analytics}, author={Lee, Jonathan}, year={2021}, month={Apr}} 

@article{Shen2021,
  title={LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis},
  author={Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},
  journal={arXiv preprint arXiv:2103.15348},
  year={2021}
}

@Comment{jabref-meta: databaseType:biblatex;}
