@Online{Martens2021,
  author       = {Martens, Marijn and De Wolf, Ralf and Evens, Tom},
  date         = {2021},
  title        = {Algoritmes en AI in de onderwijscontext: Een studie naar de perceptie, mening en houding van leerlingen en ouders in Vlaanderen},
  url          = {https://data-en-maatschappij.ai/publicaties/survey-onderwijs-2021},
  organization = {{Kenniscentrum Data en Maatschappij}},
  urldate      = {2022-03-30},
}

@Report{Crevits2022,
  author      = {Crevits, Hilde},
  date        = {2022-03-13},
  institution = {Vlaamse Overheid Departement Economie, Wetenschap en Innovatie},
  title       = {Kwart van bedrijven gebruikt artificiële intelligentie: Vlaanderen bij beste leerlingen van de klas},
  type        = {Persbericht},
  file        = {:persbericht_-_kwart_van_bedrijven_gebruikt_artificiele_intelligentie_-_vlaanderen_bij_beste_leerlingen_van_de_klas.pdf:PDF},
}

@InProceedings{Gala2016,
  author    = {Gala, N{\'u}ria and Ziegler, Johannes},
  booktitle = {Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity ({CL}4{LC})},
  date      = {2016},
  title     = {Reducing lexical complexity as a tool to increase text accessibility for children with dyslexia},
  pages     = {59--66},
  publisher = {The COLING 2016 Organizing Committee},
  abstract  = {Lexical complexity plays a central role in readability, particularly for dyslexic children and poor readers because of their slow and laborious decoding and word recognition skills. Although some features to aid readability may be common to most languages (e.g., the majority of {`}easy{'} words are of low frequency), we believe that lexical complexity is mainly language-specific. In this paper, we define lexical complexity for French and we present a pilot study on the effects of text simplification in dyslexic children. The participants were asked to read out loud original and manually simplified versions of a standardized French text corpus and to answer comprehension questions after reading each text. The analysis of the results shows that the simplifications performed were beneficial in terms of reading speed and they reduced the number of reading errors (mainly lexical ones) without a loss in comprehension. Although the number of participants in this study was rather small (N=10), the results are promising and contribute to the development of applications in computational linguistics.},
  address   = {Osaka, Japan},
  file      = {:Reducing lexical complexity as a tool to increase text accessibility.pdf:PDF},
  year      = {2016},
}

@InProceedings{Bingel2018,
  author    = {Bingel, Joachim and Paetzold, Gustavo and S{\o}gaard, Anders},
  booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
  date      = {2018},
  title     = {{L}exi: A tool for adaptive, personalized text simplification},
  pages     = {245--258},
  publisher = {Association for Computational Linguistics},
  abstract  = {Most previous research in text simplification has aimed to develop generic solutions, assuming very homogeneous target audiences with consistent intra-group simplification needs. We argue that this assumption does not hold, and that instead we need to develop simplification systems that adapt to the individual needs of specific users. As a first step towards personalized simplification, we propose a framework for adaptive lexical simplification and introduce Lexi, a free open-source and easily extensible tool for adaptive, personalized text simplification. Lexi is easily installed as a browser extension, enabling easy access to the service for its users.},
  address   = {Santa Fe, New Mexico, USA},
  file      = {:Lexi - A tool for adaptive, personalized text simplification.pdf:PDF},
  year      = {2018},
}

@Report{Muyters2019,
  author      = {Muyters, Philippe},
  date        = {2019-03-22},
  institution = {Vlaamse Regering},
  title       = {Vlaams Beleidsplan Artificiële Intelligentie},
  file        = {:Vlaams Beleidsplan.pdf:PDF},
}

@Online{Martens2021a,
  author       = {Martens, Marijn and De Wolf, Ralf and Evens, Tom},
  date         = {2021-06-28},
  title        = {School innovation forum 2021},
  url          = {https://data-en-maatschappij.ai/nieuws/school-innovation-forum-2021},
  organization = {{Kenniscentrum Data en Maatschappij}},
  urldate      = {2022-04-01},
}

@Online{Swayamdipta2019,
  author   = {Swabha Swayamdipta},
  date     = {2019-01-22},
  title    = {Learning Challenges in Natural Language Processing},
  url      = {https://www.microsoft.com/en-us/research/video/learning-challenges-in-natural-language-processing/},
  language = {Engels},
  urldate  = {2022-04-01},
  abstract = {As the availability of data for language learning grows, the role of linguistic structure is under scrutiny. At the same time, it is imperative to closely inspect patterns in data which might present loopholes for models to obtain high performance on benchmarks. In a two-part talk, I will address each of these challenges.
First, I will introduce the paradigm of scaffolded learning. Scaffolds enable us to leverage inductive biases from one structural source for prediction of a different, but related structure, using only as much supervision as is necessary. We show that the resulting representations achieve improved performance across a range of tasks, indicating that linguistic structure remains beneficial even with powerful deep learning architectures.
In the second part of the talk, I will showcase some of the properties exhibited by NLP models in large data regimes. Even as these models report excellent performance, sometimes claimed to beat humans, a closer look reveals that predictions are not a result of complex reasoning, and the task is not being completed in a generalizable way. Instead, this success can be largely attributed to exploitation of some artifacts of annotation in the datasets. I will discuss some questions our finding raises, as well as directions for future work.},
}

@Online{Roldos2020,
  author       = {Inés Roldós},
  date         = {2020-12-22},
  title        = {Major Challenges of Natural Language Processing (NLP)},
  url          = {https://monkeylearn.com/blog/natural-language-processing-challenges/},
  organization = {MonkeyLearn},
  urldate      = {2022-04-01},
}

@Article{Siddharthan2014,
  author  = {Siddharthan, Advaith},
  title   = {A survey of research on text simplification},
  pages   = {259-298},
  volume  = {165},
  journal = {ITL - International Journal of Applied Linguistics},
  month   = {12},
  year    = {2014},
}

@Book{Chowdhary2020,
  author    = {K.R. Chowdhary},
  date      = {2020},
  title     = {Fundamentals of Artificial Intelligence},
  publisher = {Springer, New Delhi},
}

@Online{Sciforce2020,
  author   = {{Sciforce}},
  date     = {2020-02-04},
  title    = {Biggest Open Problems in Natural Language Processing},
  url      = {https://medium.com/sciforce/biggest-open-problems-in-natural-language-processing-7eb101ccfc9},
  language = {Engels},
  urldate  = {2022-04-01},
  abstract = {The NLP domain reports great advances to the extent that a number of problems, such as part-of-speech tagging, are considered to be fully solved. At the same time, such tasks as text summarization or machine dialog systems are notoriously hard to crack and remain open for the past decades.},
}

@Article{PlavenSigray2017,
  author       = {Plavén-Sigray, Pontus and Matheson, Granville James and Schiffler, Björn Christian and Thompson, William Hedley},
  title        = {Research: The readability of scientific texts is decreasing over time},
  editor       = {King, Stuart},
  issn         = {2050-084X},
  pages        = {e27725},
  volume       = {6},
  abstract     = {Clarity and accuracy of reporting are fundamental to the scientific process. Readability formulas can estimate how difficult a text is to read. Here, in a corpus consisting of 709,577 abstracts published between 1881 and 2015 from 123 scientific journals, we show that the readability of science is steadily decreasing. Our analyses show that this trend is indicative of a growing use of general scientific jargon. These results are concerning for scientists and for the wider public, as they impact both the reproducibility and accessibility of research findings.},
  article_type = {journal},
  citation     = {eLife 2017;6:e27725},
  journal      = {eLife},
  keywords     = {metascience, readability, data analysis, jargon, scientific communication},
  pub_date     = {2017-09-05},
  publisher    = {eLife Sciences Publications, Ltd},
  year         = {2017},
}

@Article{Barnett2020,
  author       = {Barnett, Adrian and Doubleday, Zoe},
  title        = {Meta-Research: The growth of acronyms in the scientific literature},
  editor       = {Rodgers, Peter},
  issn         = {2050-084X},
  pages        = {e60080},
  volume       = {9},
  abstract     = {Some acronyms are useful and are widely understood, but many of the acronyms used in scientific papers hinder understanding and contribute to the increasing fragmentation of science. Here we report the results of an analysis of more than 24 million article titles and 18 million article abstracts published between 1950 and 2019. There was at least one acronym in 19\% of the titles and 73\% of the abstracts. Acronym use has also increased over time, but the re-use of acronyms has declined. We found that from more than one million unique acronyms in our data, just over 2,000 (0.2\%) were used regularly, and most acronyms (79\%) appeared fewer than 10 times. Acronyms are not the biggest current problem in science communication, but reducing their use is a simple change that would help readers and potentially increase the value of science.},
  article_type = {journal},
  citation     = {eLife 2020;9:e60080},
  journal      = {eLife},
  keywords     = {meta-research, scientific writing, acronyms, communication, knowledge, scientific publishing},
  pub_date     = {2020-07-23},
  publisher    = {eLife Sciences Publications, Ltd},
  year         = {2020},
}

@Online{Gupta2021,
  author = {Jyoti Gupta},
  date   = {2021-01-23},
  title  = {NLP Trends and Use Cases in 2021},
  url    = {https://www.whatech.com/og/artificial-intelligence/blog/688309-nlp-trends-and-use-cases-in-2021},
}

@Article{Donato2022,
  author   = {Donato, Antonella and Muscolo, Maria and Arias Romero, Mateo and Caprì, Tindara and Calarese, Tiziana and Olmedo Moreno, Eva María},
  title    = {Students with dyslexia between school and university: Post-diploma choices and the reasons that determine them. An Italian study},
  number   = {1},
  pages    = {110-127},
  volume   = {28},
  abstract = {Although the number of students with dyslexia enrolled in Italian universities is constantly growing, their presence remains relatively limited. The aim of this study was therefore to investigate the choices made by students with dyslexia in relation to university studies, and the underlying reasons for their choices. This study also compares these choices for students with and without dyslexia. In all, 440 high school students and their families agreed to take part in this project. Socio-demographic data was collected for the 47 students with dyslexia and 47 class-matched students without dyslexia, along with information on their current schools and their future educational plans. A specially developed questionnaire was used for the students, in combination with structured interviews with their families. The results show significant differences between these groups regarding both choices for university studies and the underlying motivations for these choices. Furthermore, certain psychological and emotional factors are implicated here in the decisions of the students with dyslexia regarding both university studies and their underlying reasons. Future research is needed to further investigate these factors in the educational choices of students with dyslexia.},
  journal  = {Dyslexia},
  keywords = {choices, dyslexia, reasons, students, university},
  year     = {2022},
}

@Article{VasquezRodriguez2021,
  author     = {Laura V{\'{a}}squez{-}Rodr{\'{\i}}guez and Matthew Shardlow and Piotr Przybyla and Sophia Ananiadou},
  title      = {Investigating Text Simplification Evaluation},
  eprint     = {2107.13662},
  eprinttype = {arXiv},
  volume     = {abs/2107.13662},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2107-13662.bib},
  journal    = {CoRR},
  timestamp  = {Tue, 03 Aug 2021 14:53:34 +0200},
  year       = {2021},
}

@InProceedings{Rello2012,
  author    = {Rello, Luz and Kanvinde, Gaurang and Baeza-Yates, Ricardo},
  booktitle = {Proceedings of the International Cross-Disciplinary Conference on Web Accessibility},
  title     = {Layout Guidelines for Web Text and a Web Service to Improve Accessibility for Dyslexics},
  isbn      = {9781450310192},
  location  = {Lyon, France},
  publisher = {Association for Computing Machinery},
  series    = {W4A '12},
  abstract  = {In this paper, we offer set of guidelines and a web service that presents Web texts in a more more accessible way to people with dyslexia. The layout guidelines for developing this service are based on a user study with a group of twenty two dyslexic users. The data collected from our study combines qualitative data from interviews and questionnaires and quantitative data from tests carried out using eye tracking. We analyze and compare both kinds of data and present a set of layout guidelines for making the text Web more readable for dyslexic users. To the best of our knowledge, our methodology for defining dyslexic-friendly guidelines and our web service are novel.},
  address   = {New York, NY, USA},
  articleno = {36},
  keywords  = {browsing web service, web accessibility, dyslexia, readability, accessibility guidelines, usability tests},
  numpages  = {9},
  year      = {2012},
}

@Online{Readable2021,
  author = {Readable},
  date   = {2021},
  title  = {Flesch Reading Ease and the Flesch Kincaid Grade Level},
  url    = {https://readable.com/readability/flesch-reading-ease-flesch-kincaid-grade-level/},
}

@Online{Droogenbroeck2022,
  author = {Kelly Van Droogenbroeck},
  date   = {2022-11-23},
  title  = {Scholen krijgen meer steun om leerlingen met beperking op te vangen},
  url    = {https://www.demorgen.be/snelnieuws/scholen-krijgen-meer-steun-om-leerlingen-met-beperking-op-te-vangen~bb2469df/},
}

@Online{Miszczak2022,
  author = {Patryk Miszczak},
  date   = {2022-09-20},
  title  = {Natural Language Processing Statistics (2022)},
  url    = {https://businessolution.org/natural-language-processing-statistics/},
}

@InProceedings{Garbacea2021,
  author    = {Garbacea, Cristina and Guo, Mengtian and Carton, Samuel and Mei, Qiaozhu},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  title     = {Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification},
  doi       = {10.18653/v1/2021.acl-long.88},
  pages     = {1086--1097},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.88},
  abstract  = {Text simplification reduces the language complexity of professional content for accessibility purposes. End-to-end neural network models have been widely adopted to directly generate the simplified version of input text, usually functioning as a blackbox. We show that text simplification can be decomposed into a compact pipeline of tasks to ensure the transparency and explainability of the process. The first two steps in this pipeline are often neglected: 1) to predict whether a given piece of text needs to be simplified, and 2) if yes, to identify complex parts of the text. The two tasks can be solved separately using either lexical or deep learning methods, or solved jointly. Simply applying explainable complexity prediction as a preliminary step, the out-of-sample text simplification performance of the state-of-the-art, black-box simplification models can be improved by a large margin.},
  address   = {Online},
  year      = {2021},
}

@Article{Bulte2018,
  author       = {Bulté, Bram and Sevens, Leen and Vandeghinste, Vincent},
  title        = {Automating lexical simplification in Dutch},
  pages        = {24–48},
  url          = {https://clinjournal.org/clinj/article/view/78},
  volume       = {8},
  abstractnote = {&amp;lt;p&amp;gt;We discuss the design, development and evaluation of an automated lexical simplification tool for Dutch. A basic pipeline approach is used to perform both text adaptation and annotation. First, sentences are preprocessed and word sense disambiguation is performed. Then, the difficulty of each token is estimated by looking at their average age of acquisition and frequency in a corpus of simplified Dutch. We use Cornetto to find synonyms of words that have been identified as difficult and the SONAR500 corpus to perform reverse lemmatisation. Finally, we rely on a largescale language model to verify whether the selected replacement word fits the local context. In addition, the text is augmented with information from Wikipedia (word definitions and links). We tune and evaluate the system with sentences taken from the Flemish newspaper De Standaard. The results show that the system’s adaptation component has low coverage, since it only correctly simplifies around one in five ‘difficult’ words, but reasonable accuracy, with no grammatical errors being introduced in the text. The Wikipedia annotations have a broader coverage, but their potential for simplification needs to be further developed and more thoroughly evaluated.&amp;lt;/p&amp;gt;},
  journal      = {Computational Linguistics in the Netherlands Journal},
  year         = {2018},
}

@Online{Verhoeven2023,
  author = {Wim Verhoeven},
  date   = {2023-02-08},
  editor = {Trends},
  title  = {Applaus voor de studenten die ChatGPT gebruiken},
  url    = {https://trends.knack.be/economie/bedrijven/applaus-voor-de-studenten-die-chatgpt-gebruiken/article-opinion-1934277.html?cookie_check=1676034368},
}

@Online{Malik2022,
  author = {Rijul Sing Malik},
  date   = {2022-07-04},
  editor = {Towards AI},
  title  = {Top 5 NLP Libraries To Use in Your Projects},
  url    = {https://towardsai.net/p/l/top-5-nlp-libraries-to-use-in-your-projects},
}

@Article{Shardlow2014,
  author    = {Matthew Shardlow},
  title     = {A Survey of Automated Text Simplification},
  doi       = {10.14569/SpecialIssue.2014.040109},
  number    = {1},
  url       = {http://dx.doi.org/10.14569/SpecialIssue.2014.040109},
  volume    = {4},
  journal   = {International Journal of Advanced Computer Science and Applications(IJACSA), Special Issue on Natural Language Processing 2014},
  publisher = {The Science and Information Organization},
  year      = {2014},
}

@Article{Thangarajah2019,
  author = {Thangarajah, Vinothraj},
  title  = {Python current trend applications-an overview},
  month  = {10},
  year   = {2019},
}

@InProceedings{Iavarone2021,
  author    = {Iavarone, Benedetta and Brunato, Dominique and Dell{'}Orletta, Felice},
  booktitle = {Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},
  title     = {Sentence Complexity in Context},
  doi       = {10.18653/v1/2021.cmcl-1.23},
  pages     = {186--199},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.cmcl-1.23},
  abstract  = {We study the influence of context on how humans evaluate the complexity of a sentence in English. We collect a new dataset of sentences, where each sentence is rated for perceived complexity within different contextual windows. We carry out an in-depth analysis to detect which linguistic features correlate more with complexity judgments and with the degree of agreement among annotators. We train several regression models, using either explicit linguistic features or contextualized word embeddings, to predict the mean complexity values assigned to sentences in the different contextual windows, as well as their standard deviation. Results show that models leveraging explicit features capturing morphosyntactic and syntactic phenomena perform always better, especially when they have access to features extracted from all contextual sentences.},
  address   = {Online},
  month     = jun,
  year      = {2021},
}

@Online{Dapaah2022,
  author = {Dapaah, Josephine and Maenhout, Klaas},
  date   = {2022-07-08},
  editor = {De Standaard},
  title  = {Iedereen heeft boter op zijn hoofd},
  url    = {https://www.standaard.be/cnt/dmf20220607_97763592},
}

@inproceedings{Gooding2022,
    title = "On the Ethical Considerations of Text Simplification",
    author = "Gooding, Sian",
    booktitle = "Ninth Workshop on Speech and Language Processing for Assistive Technologies (SLPAT-2022)",
    month = "05",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.slpat-1.7",
    doi = "10.18653/v1/2022.slpat-1.7",
    pages = "50--57",
    abstract = "This paper outlines the ethical implications of text simplification within the framework of assistive systems. We argue that a distinction should be made between the technologies that perform text simplification and the realisation of these in assistive technologies. When using the latter as a motivation for research, it is important that the subsequent ethical implications be carefully considered. We provide guidelines for the framing of text simplification independently of assistive systems, as well as suggesting directions for future research and discussion based on the concerns raised.",
}

@Article{Vasista2022,
  author       = {Vasista, Kola},
  title        = {Evolution of AI Design Models},
  number       = {3},
  pages        = {1-4},
  url          = {https://www.cajotas.centralasianstudies.org/index.php/CAJOTAS/article/view/415},
  volume       = {3},
  abstractnote = {&lt;p&gt;Today, the articulation expert system, and even merely artificial intelligence, is generally and also ordinarily utilized to describe any kind of machine learning training course. Inside, it is beginning to replace &quot;large records&quot; and its very own hangers-on, &quot;sped up analytics&quot; and also &quot;predictive analytics. For those that do not like the phrase &quot;big files,&quot; this is likely an excellent idea. This paper provides business/technology trends, design models, benefits and approaches towards artificlial intellingence. This paper provides the evolution of AI Design models.&lt;/p&#38;gt;},
  journal      = {Central Asian Journal of Theoretical and Applied Science},
  month        = {Mar.},
  year         = {2022},
}


@inproceedings{Suter2016,
author = {Suter, Julia and Ebling, Sarah and Volk, Martin},
year = {2016},
month = {09},
pages = {},
title = {Rule-based Automatic Text Simplification for German}
}

@Comment{jabref-meta: databaseType:biblatex;}
